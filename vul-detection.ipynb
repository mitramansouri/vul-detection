{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "j_NV9XIPiQm5",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2ab1dd0b-0831-480a-cc02-ccc294e093c5",
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /venv/main/lib/python3.12/site-packages (2.7.0+cu128)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.12/site-packages (from torch) (70.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /venv/main/lib/python3.12/site-packages (from torch) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /venv/main/lib/python3.12/site-packages (from torch) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /venv/main/lib/python3.12/site-packages (from torch) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /venv/main/lib/python3.12/site-packages (from torch) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /venv/main/lib/python3.12/site-packages (from torch) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /venv/main/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /venv/main/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /venv/main/lib/python3.12/site-packages (from torch) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /venv/main/lib/python3.12/site-packages (from torch) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.0 in /venv/main/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /venv/main/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /venv/main/lib/python3.12/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /venv/main/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /venv/main/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /venv/main/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.52.4\n",
      "Collecting Optuna\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from Optuna)\n",
      "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from Optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.12/site-packages (from Optuna) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from Optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from Optuna)\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.12/site-packages (from Optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /venv/main/lib/python3.12/site-packages (from Optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->Optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /venv/main/lib/python3.12/site-packages (from alembic>=1.5.0->Optuna) (4.13.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->Optuna)\n",
      "  Downloading greenlet-3.2.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /venv/main/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->Optuna) (2.1.5)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.2.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (605 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.5/605.5 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, Optuna\n",
      "Successfully installed Mako-1.3.10 Optuna-4.3.0 alembic-1.16.1 colorlog-6.9.0 greenlet-3.2.3 sqlalchemy-2.0.41\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.26.0 in /venv/main/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.4-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /venv/main/lib/python3.12/site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /venv/main/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /venv/main/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.7/323.7 kB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading kiwisolver-1.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement gc (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for gc\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch # for Model inference\n",
    "!pip install transformers # for Tokenization\n",
    "!pip install Optuna\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install json\n",
    "!pip install gc\n",
    "!pip install os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /venv/main/lib/python3.12/site-packages (from scikit-learn) (2.1.2)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.0 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T14:25:18.935952Z",
     "start_time": "2025-05-16T14:25:18.820272Z"
    },
    "id": "0u883b_UiB-J",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import RobertaTokenizerFast\n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Status:\n",
      "Allocated: 0MB\n",
      "Cached: 0MB\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU memory and cache\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "\n",
    "# Print GPU memory stats to verify\n",
    "print(\"GPU Memory Status:\")\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated(0) // 1024**2}MB\")\n",
    "print(f\"Cached: {torch.cuda.memory_reserved(0) // 1024**2}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T14:20:14.037772Z",
     "start_time": "2025-05-16T14:20:13.738418Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_DbJxDiiwFU",
    "outputId": "456f75ec-9dba-4fa2-cb40-442bff861355",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 5080\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oo8akBceVSTO"
   },
   "source": [
    "##Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6yZDSMZiVR7S",
    "outputId": "764a86ad-26e4-45f9-8fd5-4c252501107d",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "5csPph-eVt7j",
    "outputId": "1447de66-acb4-43f1-fce3-28b8f29c3e11",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vulnerability Distribution:\n",
      "vul\n",
      "0    177736\n",
      "1      8794\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#build DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Value counts\n",
    "vul_counts = df['vul'].value_counts()\n",
    "\n",
    "# Print raw counts\n",
    "print(\"Vulnerability Distribution:\")\n",
    "print(vul_counts)\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(4,4))\n",
    "vul_counts.plot.pie(autopct='%1.1f%%', labels=['Not Vulnerable', 'Vulnerable'], colors=['#66b3ff','#ff9999'])\n",
    "plt.title('Vulnerability Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0yoHAiAfPIb"
   },
   "source": [
    "#Splitting Dataset to test and train_val so we dont mess up the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vul\n",
      "0    17756\n",
      "1      897\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#small dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "not_touched_df,small_dataset=train_test_split(df,test_size=0.1,random_state=42)\n",
    "\n",
    "vul_counts=small_dataset['vul'].value_counts()\n",
    "print(vul_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vulnerability Distribution:\n",
      "vul\n",
      "0    17756\n",
      "1      897\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#build DataFrame\n",
    "small_df = pd.DataFrame(small_dataset)\n",
    "\n",
    "# Value counts\n",
    "vul_counts = small_df['vul'].value_counts()\n",
    "\n",
    "# Print raw counts\n",
    "print(\"Vulnerability Distribution:\")\n",
    "print(vul_counts)\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(4,4))\n",
    "vul_counts.plot.pie(autopct='%1.1f%%', labels=['Not Vulnerable', 'Vulnerable'], colors=['#66b3ff','#ff9999'])\n",
    "plt.title('Vulnerability Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "Z2dcxvJFXWvM",
    "outputId": "029284bc-cac0-4c53-cf75-b9f009bd69f0",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vulnerability Distribution:\n",
      "vul\n",
      "0    15982\n",
      "1      805\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# keep 10% for test data about 17000 samples\n",
    "train_val_ds, test_dataset = train_test_split(small_dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_val_df = pd.DataFrame(train_val_ds)\n",
    "\n",
    "# Show first few rows\n",
    "train_val_df.head()\n",
    "\n",
    "# Value counts\n",
    "vul_counts = train_val_df['vul'].value_counts()\n",
    "\n",
    "# Print raw counts\n",
    "print(\"Vulnerability Distribution:\")\n",
    "print(vul_counts)\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(4,4))\n",
    "vul_counts.plot.pie(autopct='%1.1f%%', labels=['Not Vulnerable', 'Vulnerable'], colors=['#66b3ff','#ff9999'])\n",
    "plt.title('Vulnerability Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sKW1b_DN3Vl",
    "outputId": "c4638821-741b-46f0-a2b7-13f5661fda71",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vulnerability Distribution:\n",
      "vul\n",
      "0    1774\n",
      "1      92\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "# Convert to DataFrame\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "\n",
    "# Show first few rows\n",
    "test_df.head()\n",
    "\n",
    "# Value counts\n",
    "vul_counts = test_df['vul'].value_counts()\n",
    "\n",
    "# Print raw counts\n",
    "print(\"Vulnerability Distribution:\")\n",
    "print(vul_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2UoYZgXYmxW",
    "outputId": "78e1966c-254c-453f-c146-643206d6fa17",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vul\n",
      "0    1600\n",
      "1      79\n",
      "Name: count, dtype: int64\n",
      "vul\n",
      "0    14382\n",
      "1      726\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#build up validation data\n",
    "\n",
    "train_dataset, validation_dataset = train_test_split(train_val_ds, test_size=0.1, random_state=42)\n",
    "\n",
    "vul_counts = pd.DataFrame(validation_dataset)['vul'].value_counts()\n",
    "print(vul_counts)\n",
    "\n",
    "print(pd.DataFrame(train_dataset)['vul'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "\n",
    "small_dataset.to_csv(\"small_dataset\",index=False)\n",
    "train_dataset.to_csv(\"train_dataset\",index=False)\n",
    "validation_dataset.to_csv(\"validation_dataset\",index=False)\n",
    "test_dataset.to_csv(\"test_dataset\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "test_dataset=pd.read_csv(\"test_dataset\", converters={'flaw_line_no': ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# --- 1) Your Dataset class, modified to return subtoken→line mapping ---\n",
    "\n",
    "class CodeBERTDataset(Dataset):\n",
    "    def __init__(self, codes, tokenizer, max_length):\n",
    "        self.data       = codes\n",
    "        self.tokenizer  = tokenizer\n",
    "        self.max_len    = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        code         = item[\"code\"]\n",
    "        vul          = item[\"vul\"]\n",
    "        flaw_line_no = item[\"flaw_line_no\"]\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            code,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "        input_ids      = enc[\"input_ids\"].squeeze(0)        # (seq_len,)\n",
    "        attention_mask = enc[\"attention_mask\"].squeeze(0)   # (seq_len,)\n",
    "        offset_mapping = enc[\"offset_mapping\"].squeeze(0)   # (seq_len, 2)\n",
    "\n",
    "        # Build char -> line lookup\n",
    "        char_to_line = []\n",
    "        current_line = 0\n",
    "        for i, ch in enumerate(code):\n",
    "            char_to_line.append(current_line)\n",
    "            if ch == \"\\n\":\n",
    "                current_line += 1\n",
    "\n",
    "        # Build subtoken2line- map each subtoken back to its original line number in the source code.\n",
    "\n",
    "\n",
    "        subtoken2line = torch.zeros(input_ids.size(0), dtype=torch.long)\n",
    "        for tok_idx in range(input_ids.size(0)):\n",
    "            sc, ec = offset_mapping[tok_idx].tolist()\n",
    "            if attention_mask[tok_idx].item() == 0 or (sc == ec == 0):\n",
    "                subtoken2line[tok_idx] = -1\n",
    "            else:\n",
    "                sc = min(sc, len(char_to_line)-1)\n",
    "                subtoken2line[tok_idx] = char_to_line[sc]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\":      input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\":         torch.tensor(vul, dtype=torch.long),\n",
    "            \"code\":           code,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "            \"flaw_line_no\":   flaw_line_no,\n",
    "            \"subtoken2line\":  subtoken2line\n",
    "        }\n",
    "\n",
    "# --- 2) Collate function, stacking subtoken2line too ---\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    collated_batch = {}\n",
    "    collated_batch[\"input_ids\"]      = torch.stack([item[\"input_ids\"]      for item in batch])\n",
    "    collated_batch[\"attention_mask\"] = torch.stack([item[\"attention_mask\"] for item in batch])\n",
    "    collated_batch[\"labels\"]         = torch.stack([item[\"labels\"]         for item in batch])\n",
    "    collated_batch[\"offset_mapping\"] = torch.stack([item[\"offset_mapping\"] for item in batch])\n",
    "    collated_batch[\"subtoken2line\"]  = torch.stack([item[\"subtoken2line\"]  for item in batch])\n",
    "\n",
    "    # Keep strings/lists as-is\n",
    "    collated_batch[\"code\"]         = [item[\"code\"]         for item in batch]\n",
    "    collated_batch[\"flaw_line_no\"] = [item[\"flaw_line_no\"] for item in batch]\n",
    "\n",
    "    return collated_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f386b436fe0f41dda6294bc8018fac8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d9f3d7d4d146fbb398ede5c2a7874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5e299ed3a841979cc9f034e3884dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630a681b98524ee6a6f76359dd3ba8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bc8d85f5624da292d80a110a864c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c06a6771034df7958f782284b07dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "RobertaSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32a6c77e05744aa8bc66ea5165a7dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train_loss=0.2611, train_acc=0.881\n",
      "[Epoch 1] val_loss=0.1584, val_acc=0.953, val_prec=0.000, val_rec=0.000, val_f1=0.000, val_mcc=0.000\n",
      "[Epoch 2] train_loss=0.1398, train_acc=0.959\n",
      "[Epoch 2] val_loss=0.1013, val_acc=0.968, val_prec=0.903, val_rec=0.354, val_f1=0.509, val_mcc=0.555\n",
      "[Epoch 3] train_loss=0.0963, train_acc=0.973\n",
      "[Epoch 3] val_loss=0.0656, val_acc=0.980, val_prec=0.803, val_rec=0.772, val_f1=0.787, val_mcc=0.777\n",
      "[Epoch 4] train_loss=0.0829, train_acc=0.978\n",
      "[Epoch 4] val_loss=0.0715, val_acc=0.980, val_prec=0.811, val_rec=0.759, val_f1=0.784, val_mcc=0.774\n",
      "[Epoch 5] train_loss=0.0756, train_acc=0.980\n",
      "[Epoch 5] val_loss=0.0610, val_acc=0.982, val_prec=0.810, val_rec=0.810, val_f1=0.810, val_mcc=0.801\n",
      "[Epoch 6] train_loss=0.0658, train_acc=0.982\n",
      "[Epoch 6] val_loss=0.0765, val_acc=0.983, val_prec=0.821, val_rec=0.810, val_f1=0.815, val_mcc=0.806\n",
      "[Epoch 7] train_loss=0.0573, train_acc=0.984\n",
      "[Epoch 7] val_loss=0.0620, val_acc=0.983, val_prec=0.868, val_rec=0.747, val_f1=0.803, val_mcc=0.796\n",
      "[Epoch 8] train_loss=0.0496, train_acc=0.987\n",
      "[Epoch 8] val_loss=0.0774, val_acc=0.983, val_prec=0.870, val_rec=0.759, val_f1=0.811, val_mcc=0.804\n",
      "[Epoch 9] train_loss=0.0417, train_acc=0.988\n",
      "[Epoch 9] val_loss=0.0716, val_acc=0.982, val_prec=0.818, val_rec=0.797, val_f1=0.808, val_mcc=0.798\n",
      "[Epoch 10] train_loss=0.0380, train_acc=0.990\n",
      "[Epoch 10] val_loss=0.0752, val_acc=0.985, val_prec=0.873, val_rec=0.785, val_f1=0.827, val_mcc=0.820\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- 3) Hyperparameters & setup ---\n",
    "\n",
    "lr         = 1e-5\n",
    "bs         = 16\n",
    "msl        = 512\n",
    "max_epochs = 10\n",
    "wd=0.1\n",
    "\n",
    "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"microsoft/codebert-base\")\n",
    "model     = RobertaForSequenceClassification.from_pretrained(\n",
    "                \"microsoft/codebert-base\",\n",
    "                num_labels=2,\n",
    "                output_attentions=True  # <-- request attentions here\n",
    "            ).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr,weight_decay=wd)\n",
    "\n",
    "train_ds = CodeBERTDataset(train_dataset, tokenizer, msl)\n",
    "val_ds   = CodeBERTDataset(validation_dataset,   tokenizer, msl)\n",
    "test_ds  = CodeBERTDataset(test_dataset,         tokenizer, msl)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=bs, shuffle=True,  collate_fn=custom_collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=bs, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=bs, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "total_steps  = len(train_loader) * max_epochs\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps,\n",
    ")\n",
    "\n",
    "# --- 4) Training + validation loop for function‐level only ---\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    # ----- TRAIN -----\n",
    "    model.train()\n",
    "    train_loss   = []\n",
    "    train_preds  = []\n",
    "    train_labels = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(\n",
    "            input_ids=batch[\"input_ids\"].to(device),\n",
    "            attention_mask=batch[\"attention_mask\"].to(device),\n",
    "            labels=batch[\"labels\"].to(device),\n",
    "            # output_attentions=True is already set in model_init\n",
    "        )\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        preds = out.logits.argmax(dim=1).cpu().tolist()\n",
    "        train_preds.extend(preds)\n",
    "        train_labels.extend(batch[\"labels\"].tolist())\n",
    "\n",
    "    avg_train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = accuracy_score(train_labels, train_preds)\n",
    "    print(f\"[Epoch {epoch+1}] train_loss={avg_train_loss:.4f}, train_acc={train_acc:.3f}\")\n",
    "\n",
    "    # ----- VALIDATION (function‐level) -----\n",
    "    model.eval()\n",
    "    val_loss   = []\n",
    "    val_preds  = []\n",
    "    val_lbls   = []\n",
    "    with torch.no_grad():\n",
    "        for b in val_loader:\n",
    "            out = model(\n",
    "                input_ids=b[\"input_ids\"].to(device),\n",
    "                attention_mask=b[\"attention_mask\"].to(device),\n",
    "                labels=b[\"labels\"].to(device)\n",
    "            )\n",
    "            val_loss.append(out.loss.item())\n",
    "            val_logits = out.logits.cpu()\n",
    "            val_preds.extend(val_logits.argmax(dim=1).tolist())\n",
    "            val_lbls.extend(b[\"labels\"].tolist())\n",
    "\n",
    "    avg_val_loss = sum(val_loss) / len(val_loss)\n",
    "    val_acc  = accuracy_score(val_lbls, val_preds)\n",
    "    val_prec = precision_score(val_lbls, val_preds, zero_division=0)\n",
    "    val_rec  = recall_score(val_lbls, val_preds, zero_division=0)\n",
    "    val_f1   = f1_score(val_lbls, val_preds, zero_division=0)\n",
    "    val_mcc  = matthews_corrcoef(val_lbls, val_preds)\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] \"\n",
    "          f\"val_loss={avg_val_loss:.4f}, val_acc={val_acc:.3f}, \"\n",
    "          f\"val_prec={val_prec:.3f}, val_rec={val_rec:.3f}, \"\n",
    "          f\"val_f1={val_f1:.3f}, val_mcc={val_mcc:.3f}\")\n",
    "\n",
    "# At this point you have a trained model (fine‐tuned to maximize F1 on val set).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fine-tuned model and tokenizer to: saved_codebert_checkpoint\n"
     ]
    }
   ],
   "source": [
    "save_directory = \"saved_codebert_checkpoint\"\n",
    "\n",
    "# (1) Create the output folder if it doesn’t exist\n",
    "import os\n",
    "if not os.path.isdir(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# (2) Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# (3) Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Saved fine-tuned model and tokenizer to: {save_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "save_directory = \"saved_codebert_checkpoint\"\n",
    "#Hyperparameters & setup ---\n",
    "\n",
    "lr         = 2e-5\n",
    "bs         = 16\n",
    "msl        = 512\n",
    "max_epochs = 10\n",
    "\n",
    "# Load the tokenizer and model from that directory\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(save_directory)\n",
    "model = (\n",
    "    RobertaForSequenceClassification.from_pretrained(save_directory, output_attentions=True)\n",
    "    .to(device)\n",
    ")\n",
    "test_ds  = CodeBERTDataset(test_dataset,tokenizer, msl)\n",
    "\n",
    "\n",
    "test_loader  = DataLoader(test_ds,batch_size=bs, shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function‐level (test) → acc=0.983, prec=0.895, rec=0.739, f1=0.810, mcc=0.805\n",
      "Top-10 precision (vulnerable-only) = 0.632\n",
      "Top-10 recall (vulnerable-only) = 0.522\n",
      "Initial False Alarm (average) = 8.51 lines before true flaw\n",
      "Initial False Alarm (median) = 5.50 lines before true flaw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_fun_preds  = []\n",
    "all_fun_labels = []\n",
    "all_line_preds  = []\n",
    "all_line_labels = []\n",
    "line_level_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    fn_global_idx = 0\n",
    "    for b in test_loader:\n",
    "        input_ids      = b[\"input_ids\"].to(device)\n",
    "        attention_mask = b[\"attention_mask\"].to(device)\n",
    "        labels         = b[\"labels\"].to(device)       # (batch_size,)\n",
    "        sub2line       = b[\"subtoken2line\"]           # (batch_size, seq_len)\n",
    "        flaw_lines     = b[\"flaw_line_no\"]             # list of length batch_size\n",
    "\n",
    "        out     = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        logits  = out.logits           # (batch_size, 2)\n",
    "        fun_preds = logits.argmax(dim=1).cpu().tolist()\n",
    "\n",
    "        #Accumulate function-level predictions/labels\n",
    "        all_fun_preds.extend(fun_preds)\n",
    "        all_fun_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "        #Build subtoken-level “CLS→subtoken” scores\n",
    "        all_attn   = out.attentions   #is a tuple of length 12 (one tensor per Transformer layer).\n",
    "        # Stack dims → (12, batch, heads, seq_len, seq_len)\n",
    "        attn_tensor = torch.stack(all_attn, dim=0)\n",
    "        # Sum over heads → (12, batch, seq_len, seq_len)\n",
    "        attn_per_layer = attn_tensor.sum(dim=2)\n",
    "        # Sum over layers → (batch, seq_len, seq_len)\n",
    "        attn_sum = attn_per_layer.sum(dim=0)\n",
    "        # subtoken_scores[i, j] = attention from CLS (pos 0) → subtoken j of example i\n",
    "        subtoken_scores = attn_sum[:, 0, :]   # (batch_size, seq_len)\n",
    "\n",
    "        batch_size = logits.size(0)\n",
    "        for i in range(batch_size):\n",
    "            # if fun_preds[i] == 1:\n",
    "            #Gather subtoken‐scores for example i\n",
    "            st_scores = subtoken_scores[i].cpu()     # (seq_len,)\n",
    "            st2line   = sub2line[i]                  # (seq_len,)\n",
    "\n",
    "            #Build line2subtoken‐scores map\n",
    "            line2scores = {}\n",
    "            for tok_idx in range(st2line.size(0)):\n",
    "                ln = st2line[tok_idx].item()\n",
    "                if ln < 0:\n",
    "                    continue\n",
    "                score_j = st_scores[tok_idx].item()\n",
    "                line2scores.setdefault(ln, []).append(score_j)\n",
    "\n",
    "            #Sum each line’s scores\n",
    "            line2score_sum = {ln: sum(scores) for ln, scores in line2scores.items()}\n",
    "            \n",
    "            #Store for everyone\n",
    "            # line2score_map[fn_global_idx] = line2score_sum\n",
    "\n",
    "            if fun_preds[i] == 1:\n",
    "                \n",
    "            #Pick the line with the highest summed score\n",
    "                if len(line2score_sum) > 0:\n",
    "                    # sorted_lines = sorted(line2score_sum.items(),\n",
    "                    #                       key=lambda x: x[1],\n",
    "                    #                       reverse=True)\n",
    "                    pred_line = line2score_sum\n",
    "\n",
    "                else:\n",
    "                    pred_line = -1\n",
    "            else:\n",
    "                # If somehow every token was padding (line2score_sum empty), pick -1\n",
    "                pred_line = -1\n",
    "\n",
    "            line_level_results.append((fn_global_idx, pred_line))\n",
    "            # else:\n",
    "                # Model predicted “clean” → no line predicted\n",
    "                # pred_line = -1\n",
    "\n",
    "            # e) Accumulate predicted line & true line\n",
    "            # all_line_preds.append((fn_global_idx, line2score_sum))\n",
    "            \n",
    "            # If flaw_lines[i] is a list (e.g. [5]), take the first element; else treat it as int\n",
    "            gt = flaw_lines[i]\n",
    "            if isinstance(gt, (list, tuple)) and len(gt) > 0:\n",
    "                true_line = gt[0]\n",
    "            elif isinstance(gt, (list, tuple)) and len(gt) == 0:\n",
    "                true_line = -1\n",
    "            else:\n",
    "                true_line = gt\n",
    "            all_line_labels.append(true_line)\n",
    "\n",
    "            fn_global_idx += 1\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Function‐level metrics (over the entire test set)\n",
    "# ----------------------------------------------------------------------------\n",
    "test_acc  = accuracy_score(all_fun_labels, all_fun_preds)\n",
    "test_prec = precision_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_rec  = recall_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_f1   = f1_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_mcc  = matthews_corrcoef(all_fun_labels, all_fun_preds)\n",
    "print(f\"Function‐level (test) → \"\n",
    "      f\"acc={test_acc:.3f}, prec={test_prec:.3f}, rec={test_rec:.3f}, \"\n",
    "      f\"f1={test_f1:.3f}, mcc={test_mcc:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Top-K precision (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul = 0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if line2score_dict != -1:\n",
    "        total_vul +=1\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines[:K]:\n",
    "            hits += 1\n",
    "\n",
    "topk_precision = hits / total_vul\n",
    "\n",
    "print(f\"Top-{K} precision (vulnerable-only) = {topk_precision:.3f}\")\n",
    "\n",
    "# Top-K recall (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul=0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if (line2score_dict != -1): # & (true_line !=-1)):\n",
    "        total_vul +=1\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines[:K]:\n",
    "            hits += 1\n",
    "\n",
    "total_vul = len(all_line_labels) - all_line_labels.count(-1)\n",
    "topk_recall = hits / total_vul\n",
    "\n",
    "print(f\"Top-{K} recall (vulnerable-only) = {topk_recall:.3f}\")\n",
    "\n",
    "import statistics\n",
    "# Initial False Alarm (IFA)\n",
    "ifa_list = []\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if (line2score_dict != -1):\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines:\n",
    "            pos = ranked_lines.index(true_line)\n",
    "        else:\n",
    "            pos = len(ranked_lines)\n",
    "        ifa_list.append(pos)\n",
    "\n",
    "if len(ifa_list) > 0:\n",
    "    avg_ifa = sum(ifa_list) / len(ifa_list)\n",
    "    med_ifa = statistics.median(ifa_list)\n",
    "else:\n",
    "    avg_ifa = 0.0\n",
    "\n",
    "print(f\"Initial False Alarm (average) = {avg_ifa:.2f} lines before true flaw\")\n",
    "print(f\"Initial False Alarm (median) = {med_ifa:.2f} lines before true flaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function‐level (test) → acc=0.983, prec=0.895, rec=0.739, f1=0.810, mcc=0.805\n",
      "Top-10 precision (vulnerable-only) = 0.447\n",
      "Top-10 recall (vulnerable-only) = 0.370\n",
      "Initial False Alarm (average) = 10.87 lines before true flaw\n",
      "Initial False Alarm (median) = 8.50 lines before true flaw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_fun_preds  = []\n",
    "all_fun_labels = []\n",
    "all_line_preds  = []\n",
    "all_line_labels = []\n",
    "line_level_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    fn_global_idx = 0\n",
    "    for b in test_loader:\n",
    "        input_ids      = b[\"input_ids\"].to(device)\n",
    "        attention_mask = b[\"attention_mask\"].to(device)\n",
    "        labels         = b[\"labels\"].to(device)       # (batch_size,)\n",
    "        sub2line       = b[\"subtoken2line\"]           # (batch_size, seq_len)\n",
    "        flaw_lines     = b[\"flaw_line_no\"]             # list of length batch_size\n",
    "\n",
    "        out     = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        logits  = out.logits           # (batch_size, 2)\n",
    "        fun_preds = logits.argmax(dim=1).cpu().tolist()\n",
    "\n",
    "        #Accumulate function-level predictions/labels\n",
    "        all_fun_preds.extend(fun_preds)\n",
    "        all_fun_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "        #Build subtoken-level “CLS→subtoken” scores\n",
    "        all_attn   = out.attentions   #is a tuple of length 12 (one tensor per Transformer layer).\n",
    "        # Stack dims → (12, batch, heads, seq_len, seq_len)\n",
    "        attn_tensor = torch.stack(all_attn, dim=0)\n",
    "        # avg over heads → (12, batch, seq_len, seq_len)\n",
    "        attn_per_layer = attn_tensor.sum(dim=2)\n",
    "        # Sum over layers → (batch, seq_len, seq_len)\n",
    "        attn_avg = attn_per_layer.sum(dim=0)\n",
    "        # subtoken_scores[i, j] = attention from CLS (pos 0) → subtoken j of example i\n",
    "        subtoken_scores = attn_avg[:, 0, :]   # (batch_size, seq_len)\n",
    "\n",
    "        batch_size = logits.size(0)\n",
    "        for i in range(batch_size):\n",
    "            # if fun_preds[i] == 1:\n",
    "            #Gather subtoken‐scores for example i\n",
    "            st_scores = subtoken_scores[i].cpu()     # (seq_len,)\n",
    "            st2line   = sub2line[i]                  # (seq_len,)\n",
    "\n",
    "            #Build line2subtoken‐scores map\n",
    "            line2scores = {}\n",
    "            for tok_idx in range(st2line.size(0)):\n",
    "                ln = st2line[tok_idx].item()\n",
    "                if ln < 0:\n",
    "                    continue\n",
    "                score_j = st_scores[tok_idx].item()\n",
    "                line2scores.setdefault(ln, []).append(score_j)\n",
    "\n",
    "            #Sum each line’s scores\n",
    "            line2score_sum = {ln: max(scores) for ln, scores in line2scores.items()}\n",
    "            \n",
    "            #Store for everyone\n",
    "            # line2score_map[fn_global_idx] = line2score_sum\n",
    "\n",
    "            if fun_preds[i] == 1:\n",
    "                \n",
    "            #Pick the line with the highest summed score\n",
    "                if len(line2score_sum) > 0:\n",
    "                    # sorted_lines = sorted(line2score_sum.items(),\n",
    "                    #                       key=lambda x: x[1],\n",
    "                    #                       reverse=True)\n",
    "                    pred_line = line2score_sum\n",
    "\n",
    "                else:\n",
    "                    pred_line = -1\n",
    "            else:\n",
    "                # If somehow every token was padding (line2score_sum empty), pick -1\n",
    "                pred_line = -1\n",
    "\n",
    "            line_level_results.append((fn_global_idx, pred_line))\n",
    "            # else:\n",
    "                # Model predicted “clean” → no line predicted\n",
    "                # pred_line = -1\n",
    "\n",
    "            # e) Accumulate predicted line & true line\n",
    "            # all_line_preds.append((fn_global_idx, line2score_sum))\n",
    "            \n",
    "            # If flaw_lines[i] is a list (e.g. [5]), take the first element; else treat it as int\n",
    "            gt = flaw_lines[i]\n",
    "            if isinstance(gt, (list, tuple)) and len(gt) > 0:\n",
    "                true_line = gt[0]\n",
    "            elif isinstance(gt, (list, tuple)) and len(gt) == 0:\n",
    "                true_line = -1\n",
    "            else:\n",
    "                true_line = gt\n",
    "            all_line_labels.append(true_line)\n",
    "\n",
    "            fn_global_idx += 1\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Function‐level metrics (over the entire test set)\n",
    "# ----------------------------------------------------------------------------\n",
    "test_acc  = accuracy_score(all_fun_labels, all_fun_preds)\n",
    "test_prec = precision_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_rec  = recall_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_f1   = f1_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_mcc  = matthews_corrcoef(all_fun_labels, all_fun_preds)\n",
    "print(f\"Function‐level (test) → \"\n",
    "      f\"acc={test_acc:.3f}, prec={test_prec:.3f}, rec={test_rec:.3f}, \"\n",
    "      f\"f1={test_f1:.3f}, mcc={test_mcc:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Top-K precision (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul = 0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if line2score_dict != -1:\n",
    "        total_vul +=1\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines[:K]:\n",
    "            hits += 1\n",
    "\n",
    "topk_precision = hits / total_vul\n",
    "\n",
    "print(f\"Top-{K} precision (vulnerable-only) = {topk_precision:.3f}\")\n",
    "\n",
    "# Top-K recall (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul=0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if (line2score_dict != -1): # & (true_line !=-1)):\n",
    "        total_vul +=1\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines[:K]:\n",
    "            hits += 1\n",
    "\n",
    "total_vul = len(all_line_labels) - all_line_labels.count(-1)\n",
    "topk_recall = hits / total_vul\n",
    "\n",
    "print(f\"Top-{K} recall (vulnerable-only) = {topk_recall:.3f}\")\n",
    "\n",
    "import statistics\n",
    "# Initial False Alarm (IFA)\n",
    "ifa_list = []\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if (line2score_dict != -1):\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines:\n",
    "            pos = ranked_lines.index(true_line)\n",
    "        else:\n",
    "            pos = len(ranked_lines)\n",
    "        ifa_list.append(pos)\n",
    "\n",
    "if len(ifa_list) > 0:\n",
    "    avg_ifa = sum(ifa_list) / len(ifa_list)\n",
    "    med_ifa = statistics.median(ifa_list)\n",
    "else:\n",
    "    avg_ifa = 0.0\n",
    "\n",
    "print(f\"Initial False Alarm (average) = {avg_ifa:.2f} lines before true flaw\")\n",
    "print(f\"Initial False Alarm (median) = {med_ifa:.2f} lines before true flaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function‐level (test) → acc=0.983, prec=0.895, rec=0.739, f1=0.810, mcc=0.805\n",
      "Top-10 precision (vulnerable-only) = 0.408\n",
      "Top-10 recall (vulnerable-only) = 0.337\n",
      "Initial False Alarm (average) = 13.04 lines before true flaw\n",
      "Initial False Alarm (median) = 10.00 lines before true flaw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_fun_preds  = []\n",
    "all_fun_labels = []\n",
    "all_line_preds  = []\n",
    "all_line_labels = []\n",
    "line_level_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    fn_global_idx = 0\n",
    "    for b in test_loader:\n",
    "        input_ids      = b[\"input_ids\"].to(device)\n",
    "        attention_mask = b[\"attention_mask\"].to(device)\n",
    "        labels         = b[\"labels\"].to(device)       # (batch_size,)\n",
    "        sub2line       = b[\"subtoken2line\"]           # (batch_size, seq_len)\n",
    "        flaw_lines     = b[\"flaw_line_no\"]             # list of length batch_size\n",
    "\n",
    "        out     = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        logits  = out.logits           # (batch_size, 2)\n",
    "        fun_preds = logits.argmax(dim=1).cpu().tolist()\n",
    "\n",
    "        #Accumulate function-level predictions/labels\n",
    "        all_fun_preds.extend(fun_preds)\n",
    "        all_fun_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "        #Build subtoken-level “CLS→subtoken” scores\n",
    "        all_attn   = out.attentions   #is a tuple of length 12 (one tensor per Transformer layer).\n",
    "        # Stack dims → (12, batch, heads, seq_len, seq_len)\n",
    "        attn_tensor = torch.stack(all_attn, dim=0)\n",
    "        # avg over heads → (12, batch, seq_len, seq_len)\n",
    "        attn_per_layer = attn_tensor.sum(dim=2)\n",
    "        # Sum over layers → (batch, seq_len, seq_len)\n",
    "        attn_sum = attn_per_layer.sum(dim=0)\n",
    "        # subtoken_scores[i, j] = attention from CLS (pos 0) → subtoken j of example i\n",
    "        subtoken_scores = attn_sum[:, 0, :]   # (batch_size, seq_len)\n",
    "\n",
    "        batch_size = logits.size(0)\n",
    "        for i in range(batch_size):\n",
    "            # if fun_preds[i] == 1:\n",
    "            #Gather subtoken‐scores for example i\n",
    "            st_scores = subtoken_scores[i].cpu()     # (seq_len,)\n",
    "            st2line   = sub2line[i]                  # (seq_len,)\n",
    "\n",
    "            #Build line2subtoken‐scores map\n",
    "            line2scores = {}\n",
    "            for tok_idx in range(st2line.size(0)):\n",
    "                ln = st2line[tok_idx].item()\n",
    "                if ln < 0:\n",
    "                    continue\n",
    "                score_j = st_scores[tok_idx].item()\n",
    "                line2scores.setdefault(ln, []).append(score_j)\n",
    "\n",
    "            #Sum each line’s scores\n",
    "            line2score_sum = {ln: (sum(scores)/len(scores)) for ln, scores in line2scores.items()}\n",
    "            \n",
    "            #Store for everyone\n",
    "            # line2score_map[fn_global_idx] = line2score_sum\n",
    "\n",
    "            if fun_preds[i] == 1:\n",
    "                \n",
    "            #Pick the line with the highest summed score\n",
    "                if len(line2score_sum) > 0:\n",
    "                    # sorted_lines = sorted(line2score_sum.items(),\n",
    "                    #                       key=lambda x: x[1],\n",
    "                    #                       reverse=True)\n",
    "                    pred_line = line2score_sum\n",
    "\n",
    "                else:\n",
    "                    pred_line = -1\n",
    "            else:\n",
    "                # If somehow every token was padding (line2score_sum empty), pick -1\n",
    "                pred_line = -1\n",
    "\n",
    "            line_level_results.append((fn_global_idx, pred_line))\n",
    "            # else:\n",
    "                # Model predicted “clean” → no line predicted\n",
    "                # pred_line = -1\n",
    "\n",
    "            # e) Accumulate predicted line & true line\n",
    "            # all_line_preds.append((fn_global_idx, line2score_sum))\n",
    "            \n",
    "            # If flaw_lines[i] is a list (e.g. [5]), take the first element; else treat it as int\n",
    "            gt = flaw_lines[i]\n",
    "            if isinstance(gt, (list, tuple)) and len(gt) > 0:\n",
    "                true_line = gt[0]\n",
    "            elif isinstance(gt, (list, tuple)) and len(gt) == 0:\n",
    "                true_line = -1\n",
    "            else:\n",
    "                true_line = gt\n",
    "            all_line_labels.append(true_line)\n",
    "\n",
    "            fn_global_idx += 1\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Function‐level metrics (over the entire test set)\n",
    "# ----------------------------------------------------------------------------\n",
    "test_acc  = accuracy_score(all_fun_labels, all_fun_preds)\n",
    "test_prec = precision_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_rec  = recall_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_f1   = f1_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_mcc  = matthews_corrcoef(all_fun_labels, all_fun_preds)\n",
    "print(f\"Function‐level (test) → \"\n",
    "      f\"acc={test_acc:.3f}, prec={test_prec:.3f}, rec={test_rec:.3f}, \"\n",
    "      f\"f1={test_f1:.3f}, mcc={test_mcc:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Top-K precision (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul = 0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if line2score_dict != -1:\n",
    "        total_vul +=1\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines[:K]:\n",
    "            hits += 1\n",
    "\n",
    "topk_precision = hits / total_vul\n",
    "\n",
    "print(f\"Top-{K} precision (vulnerable-only) = {topk_precision:.3f}\")\n",
    "\n",
    "# Top-K recall (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul=0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if (line2score_dict != -1): # & (true_line !=-1)):\n",
    "        total_vul +=1\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines[:K]:\n",
    "            hits += 1\n",
    "\n",
    "total_vul = len(all_line_labels) - all_line_labels.count(-1)\n",
    "topk_recall = hits / total_vul\n",
    "\n",
    "print(f\"Top-{K} recall (vulnerable-only) = {topk_recall:.3f}\")\n",
    "\n",
    "import statistics\n",
    "# Initial False Alarm (IFA)\n",
    "ifa_list = []\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if (line2score_dict != -1):\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines:\n",
    "            pos = ranked_lines.index(true_line)\n",
    "        else:\n",
    "            pos = len(ranked_lines)\n",
    "        ifa_list.append(pos)\n",
    "\n",
    "if len(ifa_list) > 0:\n",
    "    avg_ifa = sum(ifa_list) / len(ifa_list)\n",
    "    med_ifa = statistics.median(ifa_list)\n",
    "else:\n",
    "    avg_ifa = 0.0\n",
    "\n",
    "print(f\"Initial False Alarm (average) = {avg_ifa:.2f} lines before true flaw\")\n",
    "print(f\"Initial False Alarm (median) = {med_ifa:.2f} lines before true flaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (fn_idx, line2score_dict) in line_level_results:\n",
    "#     print(line2score_dict != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 precision (vulnerable-only) = 0.632\n"
     ]
    }
   ],
   "source": [
    "# Top-K precision (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul = 0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if line2score_dict != -1:\n",
    "        total_vul +=1\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines[:K]:\n",
    "            hits += 1\n",
    "\n",
    "topk_precision = hits / total_vul\n",
    "\n",
    "print(f\"Top-{K} precision (vulnerable-only) = {topk_precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 recall (vulnerable-only) = 0.522\n"
     ]
    }
   ],
   "source": [
    "# Top-K recall (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul=0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if (line2score_dict != -1): # & (true_line !=-1)):\n",
    "        total_vul +=1\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines[:K]:\n",
    "            hits += 1\n",
    "\n",
    "total_vul = len(all_line_labels) - all_line_labels.count(-1)\n",
    "topk_recall = hits / total_vul\n",
    "\n",
    "print(f\"Top-{K} recall (vulnerable-only) = {topk_recall:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial False Alarm (average) = 8.51 lines before true flaw\n",
      "Initial False Alarm (median) = 5.50 lines before true flaw\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "# Initial False Alarm (IFA)\n",
    "ifa_list = []\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if (line2score_dict != -1):\n",
    "        ranked_lines = [\n",
    "            ln for (ln, _) \n",
    "            in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        if true_line in ranked_lines:\n",
    "            pos = ranked_lines.index(true_line)\n",
    "        else:\n",
    "            pos = len(ranked_lines)\n",
    "        ifa_list.append(pos)\n",
    "\n",
    "if len(ifa_list) > 0:\n",
    "    avg_ifa = sum(ifa_list) / len(ifa_list)\n",
    "    med_ifa = statistics.median(ifa_list)\n",
    "else:\n",
    "    avg_ifa = 0.0\n",
    "\n",
    "print(f\"Initial False Alarm (average) = {avg_ifa:.2f} lines before true flaw\")\n",
    "print(f\"Initial False Alarm (median) = {med_ifa:.2f} lines before true flaw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1866"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_line_labels)\n",
    "# len(line_level_results)\n",
    "# len(all_line_labels)-all_line_labels.count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1866"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_line_labels\n",
    "# len(test_dataset)\n",
    "# line_level_results\n",
    "len(all_line_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 precision (vulnerable-only) = 0.632\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "# Top-K precision (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul = 0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    # if true_line < 0:\n",
    "    #     continue\n",
    "    total_vul += 1\n",
    "    ranked_lines = [\n",
    "        ln for (ln, _) \n",
    "        in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    if true_line in ranked_lines[:K]:\n",
    "        hits += 1\n",
    "\n",
    "if total_vul > 0:\n",
    "    topk_precision = hits / total_vul\n",
    "else:\n",
    "    topk_precision = 0.0\n",
    "\n",
    "print(f\"Top-{K} precision (vulnerable-only) = {topk_precision:.3f}\")\n",
    "\n",
    "print(total_vul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {0: 9.009245589375496,\n",
       "   1: 6.119266837835312,\n",
       "   2: 6.555999651551247,\n",
       "   3: 7.265272170305252,\n",
       "   4: 5.105043150484562,\n",
       "   5: 1.5772084668278694,\n",
       "   6: 2.317178525030613,\n",
       "   7: 3.363267906010151,\n",
       "   8: 4.722945533692837,\n",
       "   9: 4.153036467730999,\n",
       "   10: 3.2460220977663994,\n",
       "   11: 1.2087784335017204,\n",
       "   12: 1.5926831364631653,\n",
       "   13: 2.536050245165825,\n",
       "   14: 3.0493354499340057,\n",
       "   15: 3.180682122707367,\n",
       "   16: 0.6992152333259583,\n",
       "   17: 3.3660148680210114,\n",
       "   18: 4.277627162635326,\n",
       "   19: 1.9347736537456512}),\n",
       " (54,\n",
       "  {0: 8.30311743915081,\n",
       "   1: 1.6226947903633118,\n",
       "   2: 3.8136414289474487,\n",
       "   3: 4.295560009777546,\n",
       "   4: 2.9493528828024864,\n",
       "   5: 2.824452228844166,\n",
       "   6: 2.6702891886234283,\n",
       "   7: 7.771436505019665,\n",
       "   8: 5.773502863943577,\n",
       "   9: 5.783900737762451,\n",
       "   10: 4.093850560486317,\n",
       "   11: 2.002181574702263,\n",
       "   12: 3.48694084584713,\n",
       "   13: 1.8060940876603127,\n",
       "   14: 1.6690454594790936,\n",
       "   15: 2.077723652124405,\n",
       "   16: 2.2559235244989395,\n",
       "   17: 2.080599755048752,\n",
       "   18: 2.347463071346283,\n",
       "   19: 5.438582435250282,\n",
       "   20: 1.6388715505599976}),\n",
       " (55,\n",
       "  {0: 9.455420069396496,\n",
       "   1: 4.695811226963997,\n",
       "   2: 6.165866360068321,\n",
       "   3: 1.2631803452968597,\n",
       "   4: 6.585480034351349,\n",
       "   5: 5.517950192093849,\n",
       "   6: 3.059661015868187,\n",
       "   7: 2.570583015680313,\n",
       "   8: 3.2653616666793823,\n",
       "   9: 2.0228238813579082,\n",
       "   10: 3.767368294298649,\n",
       "   11: 2.6679564714431763,\n",
       "   12: 2.5420479811728,\n",
       "   13: 2.1640914902091026,\n",
       "   14: 3.5077645629644394,\n",
       "   15: 2.8938880264759064,\n",
       "   16: 2.9943226128816605,\n",
       "   17: 2.9150341488420963,\n",
       "   18: 1.5256040394306183,\n",
       "   19: 2.016230918467045,\n",
       "   20: 1.6597923934459686,\n",
       "   21: 2.756679341197014,\n",
       "   22: 1.9105940461158752,\n",
       "   23: 1.365827202796936}),\n",
       " (116,\n",
       "  {0: 3.7903621941804886,\n",
       "   1: 1.0137532949447632,\n",
       "   2: 2.417361408472061,\n",
       "   3: 2.2737647593021393,\n",
       "   4: 2.5127368569374084,\n",
       "   5: 4.101935178041458,\n",
       "   6: 1.5766296349465847,\n",
       "   7: 3.79606069624424,\n",
       "   8: 2.1635751724243164,\n",
       "   9: 4.735972352325916,\n",
       "   10: 3.344226162880659,\n",
       "   11: 1.4860673323273659,\n",
       "   12: 1.8083581328392029,\n",
       "   13: 2.0076103657484055,\n",
       "   14: 6.268989160656929,\n",
       "   15: 2.4832894764840603,\n",
       "   16: 2.9590503349900246,\n",
       "   17: 2.867681160569191,\n",
       "   18: 2.521522458642721,\n",
       "   19: 0.8268833309412003,\n",
       "   20: 1.4155677929520607,\n",
       "   21: 2.4323921650648117,\n",
       "   22: 1.1795344781130552,\n",
       "   23: 0.9964568391442299,\n",
       "   24: 1.069884030148387,\n",
       "   25: 1.0433149803429842,\n",
       "   26: 1.263183780014515,\n",
       "   27: 1.4904244933277369,\n",
       "   28: 2.0619058310985565,\n",
       "   29: 2.950864776968956,\n",
       "   30: 1.7281264290213585,\n",
       "   31: 1.8592457827180624,\n",
       "   32: 1.1388079077005386,\n",
       "   33: 2.7306815162301064,\n",
       "   34: 3.2087841890752316,\n",
       "   35: 0.7039002068340778}),\n",
       " (118,\n",
       "  {0: 14.977525860071182,\n",
       "   1: 14.595219299197197,\n",
       "   2: 12.450517475605011,\n",
       "   3: 3.8137746304273605,\n",
       "   4: 5.316644385457039,\n",
       "   5: 3.313847631216049,\n",
       "   6: 6.408713787794113,\n",
       "   7: 1.322773277759552}),\n",
       " (126,\n",
       "  {0: 15.694103837013245,\n",
       "   1: 10.56862461566925,\n",
       "   2: 7.349344611167908,\n",
       "   3: 6.602508366107941,\n",
       "   4: 5.701557278633118,\n",
       "   5: 8.674286305904388,\n",
       "   6: 1.3495732545852661}),\n",
       " (140,\n",
       "  {0: 7.9714081063866615,\n",
       "   1: 3.057493954896927,\n",
       "   2: 3.7307901233434677,\n",
       "   3: 1.3847560286521912,\n",
       "   4: 2.7948742769658566,\n",
       "   5: 2.386182926595211,\n",
       "   6: 3.722872443497181,\n",
       "   7: 2.772828981280327,\n",
       "   8: 2.614192456007004,\n",
       "   9: 2.0580979250371456,\n",
       "   10: 1.8100365698337555,\n",
       "   11: 2.556800078600645,\n",
       "   12: 2.2129362858831882,\n",
       "   13: 1.7646957766264677,\n",
       "   14: 4.05774575099349,\n",
       "   15: 2.94294411316514,\n",
       "   16: 3.50733358040452,\n",
       "   17: 2.495359018445015,\n",
       "   18: 2.0812838561832905,\n",
       "   19: 3.699087116867304,\n",
       "   20: 2.4432536587119102,\n",
       "   21: 2.864974871277809,\n",
       "   22: 3.5712201297283173,\n",
       "   23: 2.081184394657612,\n",
       "   24: 1.9911466240882874,\n",
       "   25: 5.5131782703101635,\n",
       "   26: 3.350575380027294,\n",
       "   27: 1.1032548695802689}),\n",
       " (156,\n",
       "  {0: 13.575090140104294,\n",
       "   1: 12.145969212055206,\n",
       "   2: 3.995831251144409,\n",
       "   3: 9.196688771247864,\n",
       "   4: 4.7791141122579575,\n",
       "   5: 4.280387714505196,\n",
       "   6: 8.207787819206715,\n",
       "   7: 3.6971836984157562,\n",
       "   8: 3.0166070461273193}),\n",
       " (169,\n",
       "  {0: 17.879406452178955,\n",
       "   1: 3.182489514350891,\n",
       "   2: 6.8265716433525085,\n",
       "   3: 7.3589824587106705,\n",
       "   4: 2.5212164372205734,\n",
       "   5: 2.4637515246868134,\n",
       "   6: 4.354877404868603,\n",
       "   7: 4.328269325196743,\n",
       "   8: 2.0430636778473854,\n",
       "   9: 5.4063839092850685,\n",
       "   10: 2.325388126075268,\n",
       "   11: 1.9138799235224724,\n",
       "   12: 5.991425767540932,\n",
       "   13: 1.7146708965301514}),\n",
       " (224,\n",
       "  {0: 10.705646708607674,\n",
       "   1: 5.90773606300354,\n",
       "   2: 13.687632605433464,\n",
       "   3: 6.681528635323048,\n",
       "   4: 6.169078774750233,\n",
       "   5: 6.816546738147736,\n",
       "   6: 6.300150454044342,\n",
       "   7: 2.97934627532959}),\n",
       " (245,\n",
       "  {0: 6.534826651215553,\n",
       "   1: 5.263465605676174,\n",
       "   2: 1.9539428651332855,\n",
       "   3: 3.2043673023581505,\n",
       "   4: 3.463051363825798,\n",
       "   5: 7.252295665442944,\n",
       "   6: 2.5077179074287415,\n",
       "   7: 2.871309280395508,\n",
       "   8: 2.854991242289543,\n",
       "   9: 3.0350404158234596,\n",
       "   10: 0.5182987451553345,\n",
       "   11: 2.733909372240305,\n",
       "   12: 2.1088191755115986,\n",
       "   13: 2.578888786956668,\n",
       "   14: 0.8637524247169495,\n",
       "   15: 0.5372308492660522,\n",
       "   16: 2.3639469034969807,\n",
       "   17: 1.060215875506401,\n",
       "   18: 2.4977979585528374,\n",
       "   19: 2.3081126622855663,\n",
       "   20: 2.0585016198456287,\n",
       "   21: 2.9280641563236713,\n",
       "   22: 4.595677021890879,\n",
       "   23: 4.4634601585567,\n",
       "   24: 7.225378170609474,\n",
       "   25: 1.922450065612793}),\n",
       " (274,\n",
       "  {0: 7.518260471522808,\n",
       "   1: 1.0809121429920197,\n",
       "   2: 3.125150613486767,\n",
       "   3: 2.1288718581199646,\n",
       "   4: 1.8386382013559341,\n",
       "   5: 1.9426141791045666,\n",
       "   6: 1.8447058573365211,\n",
       "   7: 1.8362947665154934,\n",
       "   8: 1.7850565910339355,\n",
       "   9: 2.7214532159268856,\n",
       "   10: 2.187258243560791,\n",
       "   11: 2.5934772342443466,\n",
       "   12: 1.5212448611855507,\n",
       "   13: 2.3737375400960445,\n",
       "   14: 2.288771167397499,\n",
       "   15: 1.6470477133989334,\n",
       "   16: 1.4629607871174812,\n",
       "   17: 1.4313050396740437,\n",
       "   18: 1.6917843706905842,\n",
       "   19: 1.562116589397192,\n",
       "   20: 1.3331544809043407,\n",
       "   21: 1.296629138290882,\n",
       "   22: 1.475943237543106,\n",
       "   23: 1.195162732154131,\n",
       "   24: 1.0644780397415161,\n",
       "   25: 1.0402869172394276,\n",
       "   26: 1.4260477311909199,\n",
       "   27: 1.634076602756977,\n",
       "   28: 1.5646294504404068,\n",
       "   29: 1.6237169727683067,\n",
       "   30: 1.8407396972179413,\n",
       "   31: 1.69689105078578,\n",
       "   32: 1.5509170703589916,\n",
       "   33: 1.7078261114656925,\n",
       "   34: 1.8096174821257591,\n",
       "   35: 1.752967707812786,\n",
       "   36: 1.9048146530985832,\n",
       "   37: 1.855458952486515,\n",
       "   38: 2.4146646186709404,\n",
       "   39: 1.2249196767807007}),\n",
       " (335,\n",
       "  {0: 9.891258873045444,\n",
       "   1: 7.465558633208275,\n",
       "   2: 2.9074506759643555,\n",
       "   3: 3.0371224358677864,\n",
       "   4: 3.4399163462221622,\n",
       "   5: 6.9037190191447735,\n",
       "   6: 3.833982415497303,\n",
       "   7: 2.106411151587963,\n",
       "   8: 4.179511848837137,\n",
       "   9: 1.847912274301052,\n",
       "   10: 2.830998867750168,\n",
       "   11: 1.8325247876346111,\n",
       "   12: 5.150196462869644,\n",
       "   13: 5.285130638629198,\n",
       "   14: 4.490262370556593,\n",
       "   15: 1.552852552384138,\n",
       "   16: 1.680033728480339,\n",
       "   17: 3.542292185127735,\n",
       "   18: 2.766395464539528,\n",
       "   19: 2.0639346837997437}),\n",
       " (363,\n",
       "  {0: 6.296384662389755,\n",
       "   1: 1.6524397730827332,\n",
       "   2: 4.509327381849289,\n",
       "   3: 3.898682087659836,\n",
       "   4: 3.6399805769324303,\n",
       "   5: 2.4754162430763245,\n",
       "   6: 2.9357403442263603,\n",
       "   7: 2.32472213357687,\n",
       "   8: 5.2089977487921715,\n",
       "   9: 2.1892440170049667,\n",
       "   10: 1.386800080537796,\n",
       "   11: 1.2314519882202148,\n",
       "   12: 5.615267381072044,\n",
       "   13: 5.17892275378108,\n",
       "   14: 4.292793244123459,\n",
       "   15: 1.5131946727633476,\n",
       "   16: 5.870307747274637,\n",
       "   17: 2.583006400614977,\n",
       "   18: 2.305802196264267,\n",
       "   19: 2.4120619520545006,\n",
       "   20: 2.7129336521029472,\n",
       "   21: 2.0063191652297974,\n",
       "   22: 1.4236554503440857,\n",
       "   23: 1.1320236921310425}),\n",
       " (391,\n",
       "  {0: 10.973211228847504,\n",
       "   1: 3.2240641117095947,\n",
       "   2: 7.965044587850571,\n",
       "   3: 7.046314686536789,\n",
       "   4: 11.952403217554092,\n",
       "   5: 7.082064852118492,\n",
       "   6: 4.978565618395805,\n",
       "   7: 5.304379999637604,\n",
       "   8: 3.922185719013214,\n",
       "   9: 1.8756483793258667}),\n",
       " (427,\n",
       "  {0: 13.203648835420609,\n",
       "   1: 3.302919715642929,\n",
       "   2: 7.208225667476654,\n",
       "   3: 4.984238013625145,\n",
       "   4: 7.305593922734261,\n",
       "   5: 5.8303768038749695,\n",
       "   6: 4.524367243051529,\n",
       "   7: 4.45270798355341,\n",
       "   8: 6.046704389154911,\n",
       "   9: 7.581051059067249,\n",
       "   10: 2.4835312366485596}),\n",
       " (436,\n",
       "  {0: 8.924682904034853,\n",
       "   1: 1.0401965379714966,\n",
       "   2: 2.6041209921240807,\n",
       "   3: 2.1902367249131203,\n",
       "   4: 1.725006878376007,\n",
       "   5: 2.65127095580101,\n",
       "   6: 2.3510319143533707,\n",
       "   7: 3.3007424026727676,\n",
       "   8: 5.326167028397322,\n",
       "   9: 3.235752657055855,\n",
       "   10: 1.3676184602081776,\n",
       "   11: 1.259934950619936,\n",
       "   12: 1.075825572013855,\n",
       "   13: 0.8357047736644745,\n",
       "   14: 1.2375250682234764,\n",
       "   15: 1.1299347653985023,\n",
       "   16: 0.8475848659873009,\n",
       "   17: 0.7283815387636423,\n",
       "   18: 0.817029669880867,\n",
       "   19: 1.2655650489032269,\n",
       "   20: 0.962984811514616,\n",
       "   21: 1.4759358242154121,\n",
       "   22: 1.3131924271583557,\n",
       "   23: 3.9536724500358105,\n",
       "   24: 1.3481118381023407,\n",
       "   25: 1.6499840170145035,\n",
       "   26: 3.5641361735761166,\n",
       "   27: 3.1896974332630634,\n",
       "   28: 1.5126964300870895,\n",
       "   29: 1.5272819995880127,\n",
       "   30: 3.5805685594677925,\n",
       "   31: 4.33055192232132,\n",
       "   32: 4.6112937815487385,\n",
       "   33: 4.602841153740883,\n",
       "   34: 1.826914008706808}),\n",
       " (444,\n",
       "  {0: 5.690947234630585,\n",
       "   1: 5.829795643687248,\n",
       "   2: 3.916542276740074,\n",
       "   3: 2.354829713702202,\n",
       "   4: 1.4441696777939796,\n",
       "   5: 2.8875095397233963,\n",
       "   6: 1.3658412545919418,\n",
       "   7: 3.764531433582306,\n",
       "   8: 1.4506851732730865,\n",
       "   9: 1.2823963835835457,\n",
       "   10: 2.25898290425539,\n",
       "   11: 3.3761452063918114,\n",
       "   12: 2.469149224460125,\n",
       "   13: 2.1360004507005215,\n",
       "   14: 1.319811835885048,\n",
       "   15: 2.124399557709694,\n",
       "   16: 2.7958516851067543,\n",
       "   17: 2.7784176394343376,\n",
       "   18: 3.3202273808419704,\n",
       "   19: 2.5071550123393536,\n",
       "   20: 1.1273278817534447,\n",
       "   21: 1.4265848100185394,\n",
       "   22: 3.388397164642811,\n",
       "   23: 1.6199400648474693,\n",
       "   24: 1.6735228933393955,\n",
       "   25: 1.1486244089901447,\n",
       "   26: 1.7806889712810516,\n",
       "   27: 4.7429288029670715,\n",
       "   28: 1.8919039815664291,\n",
       "   29: 2.1365807615220547,\n",
       "   30: 1.5211438536643982,\n",
       "   31: 1.2580134272575378}),\n",
       " (459,\n",
       "  {0: 8.066751509904861,\n",
       "   1: 7.768928438425064,\n",
       "   2: 6.147523283958435,\n",
       "   3: 4.772237375378609,\n",
       "   4: 6.607233352959156,\n",
       "   5: 2.2588438875973225,\n",
       "   6: 5.627219617366791,\n",
       "   7: 4.138535067439079,\n",
       "   8: 2.210335087031126,\n",
       "   9: 3.4822358824312687,\n",
       "   10: 3.2381300777196884,\n",
       "   11: 4.314007870852947,\n",
       "   12: 4.2193406745791435,\n",
       "   13: 5.491075202822685,\n",
       "   14: 1.894598126411438,\n",
       "   15: 1.8465272784233093}),\n",
       " (474,\n",
       "  {0: 15.61903104186058,\n",
       "   1: 0.8922030925750732,\n",
       "   2: 5.942522004246712,\n",
       "   3: 3.4078747034072876,\n",
       "   4: 2.7126462683081627,\n",
       "   5: 6.546740375459194,\n",
       "   6: 3.0349140614271164,\n",
       "   7: 1.8956105709075928,\n",
       "   8: 2.7771117463707924,\n",
       "   9: 2.7826861143112183,\n",
       "   10: 2.69576770439744,\n",
       "   11: 2.3690372481942177,\n",
       "   12: 2.563013918697834,\n",
       "   13: 5.8888177536427975,\n",
       "   14: 0.9856648221611977,\n",
       "   15: 2.9435768760740757,\n",
       "   16: 3.8088231459259987,\n",
       "   17: 4.163412645459175,\n",
       "   18: 1.9098386764526367}),\n",
       " (495,\n",
       "  {0: 20.757426649332047,\n",
       "   1: 19.746603310108185,\n",
       "   2: 13.767380356788635,\n",
       "   3: 3.203007221221924}),\n",
       " (497,\n",
       "  {0: 9.033719010651112,\n",
       "   1: 2.176060438156128,\n",
       "   2: 2.473905399441719,\n",
       "   3: 2.9516216665506363,\n",
       "   4: 3.5688436403870583,\n",
       "   5: 3.2412232607603073,\n",
       "   6: 4.286252103745937,\n",
       "   7: 2.164220701903105,\n",
       "   8: 1.653659112751484,\n",
       "   9: 4.995713908225298,\n",
       "   10: 3.4918561466038227,\n",
       "   11: 3.1193908117711544,\n",
       "   12: 2.0445066057145596,\n",
       "   13: 1.540004126727581,\n",
       "   14: 2.992880117148161,\n",
       "   15: 3.4370053745806217,\n",
       "   16: 1.2405114397406578,\n",
       "   17: 3.447259733453393,\n",
       "   18: 1.4555085077881813,\n",
       "   19: 2.5995298456400633,\n",
       "   20: 3.3074026349931955,\n",
       "   21: 1.4214650504291058,\n",
       "   22: 2.7019161731004715,\n",
       "   23: 2.6941880136728287,\n",
       "   24: 1.94581388682127,\n",
       "   25: 4.129051595926285,\n",
       "   26: 1.7728771455585957,\n",
       "   27: 0.5395846031606197}),\n",
       " (507,\n",
       "  {0: 25.636615574359894,\n",
       "   1: 1.4451182782649994,\n",
       "   2: 5.151450663805008,\n",
       "   3: 4.597718387842178,\n",
       "   4: 3.612399809062481,\n",
       "   5: 3.659784961491823,\n",
       "   6: 2.8790101259946823,\n",
       "   7: 2.365420550107956,\n",
       "   8: 2.7799323201179504,\n",
       "   9: 3.6594826206564903,\n",
       "   10: 8.565001122653484,\n",
       "   11: 4.474216908216476,\n",
       "   12: 1.5290039405226707,\n",
       "   13: 0.8546145558357239}),\n",
       " (515,\n",
       "  {0: 14.739157527685165,\n",
       "   1: 4.3345373421907425,\n",
       "   2: 4.905940994620323,\n",
       "   3: 5.599405735731125,\n",
       "   4: 6.386114627122879,\n",
       "   5: 5.322344422340393,\n",
       "   6: 4.945145815610886,\n",
       "   7: 4.669002361595631,\n",
       "   8: 3.2806009650230408,\n",
       "   9: 3.744869187474251,\n",
       "   10: 5.804470896720886}),\n",
       " (516,\n",
       "  {0: 9.318238079547882,\n",
       "   1: 5.7945714592933655,\n",
       "   2: 6.0489844381809235,\n",
       "   3: 6.457506254315376,\n",
       "   4: 5.455379605293274,\n",
       "   5: 12.219952180981636,\n",
       "   6: 5.548418067395687,\n",
       "   7: 5.6562385112047195,\n",
       "   8: 3.0771851539611816,\n",
       "   9: 1.749378740787506}),\n",
       " (517,\n",
       "  {0: 11.599448218941689,\n",
       "   1: 2.997130870819092,\n",
       "   2: 6.316576220095158,\n",
       "   3: 4.609563387930393,\n",
       "   4: 4.333865731954575,\n",
       "   5: 5.917623363435268,\n",
       "   6: 3.677997075021267,\n",
       "   7: 8.328661769628525,\n",
       "   8: 4.971634730696678,\n",
       "   9: 3.436038598418236,\n",
       "   10: 4.626831080764532,\n",
       "   11: 3.6004775762557983,\n",
       "   12: 1.8852083384990692,\n",
       "   13: 3.806585267186165,\n",
       "   14: 0.9111020863056183}),\n",
       " (561,\n",
       "  {0: 9.543985739350319,\n",
       "   1: 5.115997321903706,\n",
       "   2: 4.59651355817914,\n",
       "   3: 4.433749131858349,\n",
       "   4: 7.323949407786131,\n",
       "   5: 2.032562777400017,\n",
       "   6: 4.024810396134853,\n",
       "   7: 1.252546302974224,\n",
       "   8: 1.7102870270609856,\n",
       "   9: 3.127857506275177,\n",
       "   10: 1.0992826111614704,\n",
       "   11: 3.6007204093039036,\n",
       "   12: 2.765336848795414,\n",
       "   13: 5.913984388113022,\n",
       "   14: 1.3746255449950695,\n",
       "   15: 4.656760215759277,\n",
       "   16: 1.71993837505579,\n",
       "   17: 1.9177888482809067,\n",
       "   18: 4.3862145990133286,\n",
       "   19: 1.400653526186943,\n",
       "   20: 0.8729544430971146}),\n",
       " (639,\n",
       "  {0: 10.412275090813637,\n",
       "   1: 4.626520171761513,\n",
       "   2: 4.880722261965275,\n",
       "   3: 2.5181193500757217,\n",
       "   4: 5.02801339328289,\n",
       "   5: 3.031491532921791,\n",
       "   6: 3.6154410988092422,\n",
       "   7: 3.638221301138401,\n",
       "   8: 4.0790941417217255,\n",
       "   9: 3.2131699435412884,\n",
       "   10: 1.960810013115406,\n",
       "   11: 1.8482498079538345,\n",
       "   12: 2.114203043282032,\n",
       "   13: 2.6791502460837364,\n",
       "   14: 1.6706393733620644,\n",
       "   15: 2.9772884249687195,\n",
       "   16: 3.796380404382944,\n",
       "   17: 1.344895377755165,\n",
       "   18: 2.490411665290594,\n",
       "   19: 5.800774164497852,\n",
       "   20: 1.4335390627384186,\n",
       "   21: 2.341924101114273}),\n",
       " (647,\n",
       "  {0: 7.90608623623848,\n",
       "   1: 7.101419821381569,\n",
       "   2: 5.274311378598213,\n",
       "   3: 5.5422340258955956,\n",
       "   4: 5.374161675572395,\n",
       "   5: 5.114075131714344,\n",
       "   6: 5.3031203001737595,\n",
       "   7: 3.2724823728203773,\n",
       "   8: 4.874884802848101,\n",
       "   9: 5.491973832249641,\n",
       "   10: 6.0840296521782875,\n",
       "   11: 3.652601782232523,\n",
       "   12: 5.351845897734165,\n",
       "   13: 1.7120802402496338,\n",
       "   14: 1.7737817764282227}),\n",
       " (672,\n",
       "  {0: 14.934268593788147,\n",
       "   1: 3.0148799419403076,\n",
       "   2: 6.4288788959383965,\n",
       "   3: 2.789771154522896,\n",
       "   4: 5.456336744129658,\n",
       "   5: 4.572293907403946,\n",
       "   6: 4.8077012449502945,\n",
       "   7: 10.770135499536991,\n",
       "   8: 2.3253316953778267,\n",
       "   9: 8.660963200032711,\n",
       "   10: 1.7378430664539337,\n",
       "   11: 3.5372586771845818,\n",
       "   12: 2.4851102232933044,\n",
       "   13: 1.191313922405243}),\n",
       " (679,\n",
       "  {0: 7.460078746080399,\n",
       "   1: 5.169685810804367,\n",
       "   2: 1.7258548736572266,\n",
       "   3: 3.850165143609047,\n",
       "   4: 2.6736812442541122,\n",
       "   5: 4.148404493927956,\n",
       "   6: 2.9054913073778152,\n",
       "   7: 2.972877722233534,\n",
       "   8: 3.858439587056637,\n",
       "   9: 3.148962154984474,\n",
       "   10: 2.2883202508091927,\n",
       "   11: 3.5339731946587563,\n",
       "   12: 3.383229874074459,\n",
       "   13: 1.4757859259843826,\n",
       "   14: 1.659423615783453,\n",
       "   15: 3.674938164651394,\n",
       "   16: 1.7907535769045353,\n",
       "   17: 5.2672918029129505,\n",
       "   18: 1.832779474556446,\n",
       "   19: 2.109085723757744,\n",
       "   20: 3.3858733624219894,\n",
       "   21: 1.4547971971333027,\n",
       "   22: 1.5665334686636925,\n",
       "   23: 1.8920839950442314,\n",
       "   24: 1.1428302079439163,\n",
       "   25: 2.2152298912405968,\n",
       "   26: 2.4643458500504494,\n",
       "   27: 1.379204511642456}),\n",
       " (734,\n",
       "  {0: 9.995432496070862,\n",
       "   1: 1.2890216410160065,\n",
       "   2: 4.677874982357025,\n",
       "   3: 2.227212131023407,\n",
       "   4: 2.2221913933753967,\n",
       "   5: 1.9510091990232468,\n",
       "   6: 3.5243019238114357,\n",
       "   7: 2.3786709047853947,\n",
       "   8: 5.317069992423058,\n",
       "   9: 1.5467424839735031,\n",
       "   10: 1.6869113110005856,\n",
       "   11: 2.212393030524254,\n",
       "   12: 3.79994722828269,\n",
       "   13: 1.5267242714762688,\n",
       "   14: 1.5181822180747986,\n",
       "   15: 2.2726200446486473,\n",
       "   16: 1.7302576787769794,\n",
       "   17: 2.052420698106289,\n",
       "   18: 2.7456264309585094,\n",
       "   19: 1.4894978664815426,\n",
       "   20: 1.921219862997532,\n",
       "   21: 1.0336007606238127,\n",
       "   22: 2.0034671388566494,\n",
       "   23: 1.297446858137846,\n",
       "   24: 1.8804535418748856,\n",
       "   25: 1.839157521724701,\n",
       "   26: 2.014555051922798,\n",
       "   27: 1.2780674025416374,\n",
       "   28: 4.173214316368103,\n",
       "   29: 1.2965089231729507,\n",
       "   30: 2.8053541891276836,\n",
       "   31: 1.4519346877932549,\n",
       "   32: 2.565241865813732,\n",
       "   33: 2.6264245323836803}),\n",
       " (752,\n",
       "  {0: 13.895156621932983,\n",
       "   1: 3.900559902191162,\n",
       "   2: 7.0027342438697815,\n",
       "   3: 8.144739627838135,\n",
       "   4: 11.326657563447952,\n",
       "   5: 13.138004317879677,\n",
       "   6: 4.15919902920723,\n",
       "   7: 2.529226779937744}),\n",
       " (814,\n",
       "  {0: 5.34005244076252,\n",
       "   1: 5.0798880606889725,\n",
       "   2: 3.9576763659715652,\n",
       "   3: 2.2607592716813087,\n",
       "   4: 3.4824881851673126,\n",
       "   5: 2.543446395546198,\n",
       "   6: 2.6190574318170547,\n",
       "   7: 4.0650526732206345,\n",
       "   8: 4.268495664000511,\n",
       "   9: 2.242860544472933,\n",
       "   10: 4.166405342519283,\n",
       "   11: 2.4655602127313614,\n",
       "   12: 2.1901760045439005,\n",
       "   13: 5.183562602847815,\n",
       "   14: 1.0691649354994297,\n",
       "   15: 2.317189857363701,\n",
       "   16: 2.4735021889209747,\n",
       "   17: 1.9217713102698326,\n",
       "   18: 1.2244538106024265,\n",
       "   19: 1.7649458050727844,\n",
       "   20: 1.9019995629787445,\n",
       "   21: 4.017561808228493,\n",
       "   22: 3.163343198597431,\n",
       "   23: 2.221651002764702,\n",
       "   24: 2.231894224882126,\n",
       "   25: 1.892019685357809,\n",
       "   26: 4.856920134276152,\n",
       "   27: 1.1296967267990112}),\n",
       " (830, {0: 16.113458037376404, 1: 28.17505845427513}),\n",
       " (874,\n",
       "  {0: 10.095815375447273,\n",
       "   1: 6.572731196880341,\n",
       "   2: 6.1398754343390465,\n",
       "   3: 2.185202896595001,\n",
       "   4: 5.880514420568943,\n",
       "   5: 7.1047403216362,\n",
       "   6: 4.980027392506599,\n",
       "   7: 4.6553037613630295,\n",
       "   8: 4.764243818819523,\n",
       "   9: 2.4511731266975403,\n",
       "   10: 3.841822735965252,\n",
       "   11: 4.44600547850132,\n",
       "   12: 2.4112134017050266,\n",
       "   13: 5.921606235206127,\n",
       "   14: 1.9192147254943848}),\n",
       " (884,\n",
       "  {0: 7.506421469151974,\n",
       "   1: 3.989461749792099,\n",
       "   2: 4.3416313752532005,\n",
       "   3: 1.4181545078754425,\n",
       "   4: 5.327485099434853,\n",
       "   5: 2.697899252176285,\n",
       "   6: 2.1234906762838364,\n",
       "   7: 3.2803443782031536,\n",
       "   8: 3.1227841787040234,\n",
       "   9: 2.2538231164216995,\n",
       "   10: 3.4231750033795834,\n",
       "   11: 3.3506022430956364,\n",
       "   12: 2.0898355692625046,\n",
       "   13: 2.766462057828903,\n",
       "   14: 2.303762972354889,\n",
       "   15: 2.3116003684699535,\n",
       "   16: 2.8338556215167046,\n",
       "   17: 2.441410183906555,\n",
       "   18: 2.909167807549238,\n",
       "   19: 1.6359957940876484,\n",
       "   20: 2.142356615513563,\n",
       "   21: 1.9826879501342773,\n",
       "   22: 3.75035360455513,\n",
       "   23: 1.7887465506792068,\n",
       "   24: 2.712870169430971,\n",
       "   25: 1.9777889996767044,\n",
       "   26: 1.3728175163269043}),\n",
       " (916,\n",
       "  {0: 18.274859309196472,\n",
       "   1: 6.676691055297852,\n",
       "   2: 17.305706202983856,\n",
       "   3: 2.4670965671539307}),\n",
       " (938,\n",
       "  {0: 27.78846710920334,\n",
       "   1: 6.748721599578857,\n",
       "   2: 14.084704101085663,\n",
       "   3: 4.2232444286346436}),\n",
       " (948,\n",
       "  {0: 11.576753869652748,\n",
       "   1: 2.9027167558670044,\n",
       "   2: 7.054638147354126,\n",
       "   3: 7.530681744217873,\n",
       "   4: 3.8612058758735657,\n",
       "   5: 2.231305703520775,\n",
       "   6: 4.733901858329773,\n",
       "   7: 4.093644432723522,\n",
       "   8: 6.640028901398182,\n",
       "   9: 3.534023616462946,\n",
       "   10: 3.4849620051681995,\n",
       "   11: 3.403681702911854,\n",
       "   12: 2.4127150550484657,\n",
       "   13: 7.9154037758708,\n",
       "   14: 1.206007182598114}),\n",
       " (981, {0: 11.598818242549896, 1: 18.655270874500275, 2: 19.08647795021534}),\n",
       " (995,\n",
       "  {0: 13.00877696275711,\n",
       "   1: 4.823765993118286,\n",
       "   2: 19.81291387975216,\n",
       "   3: 14.19354011118412,\n",
       "   4: 2.7434847354888916}),\n",
       " (1004,\n",
       "  {0: 5.316346175968647,\n",
       "   1: 0.7342442572116852,\n",
       "   2: 2.6998117864131927,\n",
       "   3: 4.0014456659555435,\n",
       "   4: 2.9423471987247467,\n",
       "   5: 1.5769109167158604,\n",
       "   6: 4.5924383364617825,\n",
       "   7: 2.8584692403674126,\n",
       "   8: 2.9254764914512634,\n",
       "   9: 3.1135853193700314,\n",
       "   10: 3.800085797905922,\n",
       "   11: 3.5591063126921654,\n",
       "   12: 3.4672086145728827,\n",
       "   13: 4.437446545809507,\n",
       "   14: 1.7884980216622353,\n",
       "   15: 4.597892016172409,\n",
       "   16: 3.4305159635841846,\n",
       "   17: 2.0845139250159264,\n",
       "   18: 2.0702231377363205,\n",
       "   19: 2.7467284575104713,\n",
       "   20: 2.650129806250334,\n",
       "   21: 2.1235230676829815,\n",
       "   22: 1.8272216357290745,\n",
       "   23: 1.906442616134882,\n",
       "   24: 2.9323223270475864,\n",
       "   25: 3.154577013105154,\n",
       "   26: 4.688221320509911,\n",
       "   27: 0.3149493560194969}),\n",
       " (1020,\n",
       "  {0: 7.605356395244598,\n",
       "   1: 5.037601329386234,\n",
       "   2: 5.272458471357822,\n",
       "   3: 7.939882285892963,\n",
       "   4: 6.348947420716286,\n",
       "   5: 3.6069157756865025,\n",
       "   6: 3.651591405272484,\n",
       "   7: 2.708982437849045,\n",
       "   8: 2.1583108119666576,\n",
       "   9: 2.771608293056488,\n",
       "   10: 1.417241171002388,\n",
       "   11: 4.814310640096664,\n",
       "   12: 1.17717195302248,\n",
       "   13: 1.7062558382749557,\n",
       "   14: 3.0048926174640656,\n",
       "   15: 4.144966464489698,\n",
       "   16: 4.543692409992218,\n",
       "   17: 2.1159922778606415,\n",
       "   18: 2.3389012217521667,\n",
       "   19: 2.5325490534305573}),\n",
       " (1021,\n",
       "  {0: 6.843123145401478,\n",
       "   1: 4.314192675054073,\n",
       "   2: 5.491016946732998,\n",
       "   3: 4.013968430459499,\n",
       "   4: 2.9109454602003098,\n",
       "   5: 2.860526617616415,\n",
       "   6: 2.9254802353680134,\n",
       "   7: 3.74029790610075,\n",
       "   8: 1.9501678049564362,\n",
       "   9: 2.091827929019928,\n",
       "   10: 2.568974904716015,\n",
       "   11: 1.8136025555431843,\n",
       "   12: 1.9892504923045635,\n",
       "   13: 1.6717202253639698,\n",
       "   14: 1.854330513626337,\n",
       "   15: 2.730719342827797,\n",
       "   16: 1.4532099179923534,\n",
       "   17: 1.3870762139558792,\n",
       "   18: 2.4197233617305756,\n",
       "   19: 2.6004170030355453,\n",
       "   20: 3.8032679557800293,\n",
       "   21: 2.465083487331867,\n",
       "   22: 1.1214692704379559,\n",
       "   23: 1.52891556173563,\n",
       "   24: 1.899756532162428,\n",
       "   25: 0.9543281644582748,\n",
       "   26: 1.0898338332772255,\n",
       "   27: 1.2618427127599716,\n",
       "   28: 1.7385909259319305,\n",
       "   29: 3.699251487851143,\n",
       "   30: 2.7898478247225285,\n",
       "   31: 0.3414037898182869}),\n",
       " (1044,\n",
       "  {0: 5.165454745292664,\n",
       "   1: 2.694240592420101,\n",
       "   2: 3.076982021331787,\n",
       "   3: 1.2606321573257446,\n",
       "   4: 2.759685128927231,\n",
       "   5: 2.0495408102869987,\n",
       "   6: 2.7111771181225777,\n",
       "   7: 3.122118964791298,\n",
       "   8: 1.975728526711464,\n",
       "   9: 2.3532265573740005,\n",
       "   10: 2.7814240008592606,\n",
       "   11: 2.781947545707226,\n",
       "   12: 1.3615940250456333,\n",
       "   13: 2.703095480799675,\n",
       "   14: 1.6163753494620323,\n",
       "   15: 1.3206896558403969,\n",
       "   16: 1.1721243094652891,\n",
       "   17: 1.6046800911426544,\n",
       "   18: 2.598508518189192,\n",
       "   19: 3.0919247791171074,\n",
       "   20: 1.3745744153857231,\n",
       "   21: 1.8626936078071594,\n",
       "   22: 1.8829086869955063,\n",
       "   23: 2.9091769456863403,\n",
       "   24: 1.9316893480718136,\n",
       "   25: 1.2669241391122341,\n",
       "   26: 1.1561096124351025,\n",
       "   27: 2.716931425035,\n",
       "   28: 1.1515391282737255,\n",
       "   29: 1.3128260970115662,\n",
       "   30: 3.7353044971823692,\n",
       "   31: 1.767862968146801,\n",
       "   32: 1.884403571486473,\n",
       "   33: 1.1414870731532574,\n",
       "   34: 1.365409404039383,\n",
       "   35: 1.0561090856790543,\n",
       "   36: 1.4452360570430756,\n",
       "   37: 2.911333419382572,\n",
       "   38: 2.8359123840928078}),\n",
       " (1089,\n",
       "  {0: 5.643459290266037,\n",
       "   1: 0.9027242660522461,\n",
       "   2: 3.7862037867307663,\n",
       "   3: 3.5736037269234657,\n",
       "   4: 4.136141061782837,\n",
       "   5: 5.2435221672058105,\n",
       "   6: 4.176716670393944,\n",
       "   7: 2.1795494481921196,\n",
       "   8: 2.476210441440344,\n",
       "   9: 2.832842092961073,\n",
       "   10: 1.332600999623537,\n",
       "   11: 2.296884983778,\n",
       "   12: 1.3421641290187836,\n",
       "   13: 0.6366636455059052,\n",
       "   14: 3.3886709474027157,\n",
       "   15: 2.4281713031232357,\n",
       "   16: 0.9810145497322083,\n",
       "   17: 0.6448918581008911,\n",
       "   18: 2.9323801063001156,\n",
       "   19: 3.0566504150629044,\n",
       "   20: 1.5810902528464794,\n",
       "   21: 1.6822515092790127,\n",
       "   22: 1.6178516820073128,\n",
       "   23: 1.687349122017622,\n",
       "   24: 1.7703909501433372,\n",
       "   25: 2.3143878392875195,\n",
       "   26: 1.1368463635444641,\n",
       "   27: 2.820554129779339,\n",
       "   28: 1.4099950641393661,\n",
       "   29: 0.9571501910686493,\n",
       "   30: 4.90640926733613,\n",
       "   31: 1.8906105384230614}),\n",
       " (1182,\n",
       "  {0: 6.6114446222782135,\n",
       "   1: 3.23487227037549,\n",
       "   2: 2.2383656427264214,\n",
       "   3: 2.851507466286421,\n",
       "   4: 2.5514954142272472,\n",
       "   5: 3.2990707606077194,\n",
       "   6: 2.4674292132258415,\n",
       "   7: 3.700284294784069,\n",
       "   8: 0.781793624162674,\n",
       "   9: 2.542780812829733,\n",
       "   10: 2.7274574413895607,\n",
       "   11: 1.7504426836967468,\n",
       "   12: 2.9031045734882355,\n",
       "   13: 3.3675965927541256,\n",
       "   14: 2.3357921689748764,\n",
       "   15: 1.4792783856391907,\n",
       "   16: 3.2514831461012363,\n",
       "   17: 1.9603681936860085,\n",
       "   18: 2.603903468698263,\n",
       "   19: 2.1583552695810795,\n",
       "   20: 1.2113208919763565,\n",
       "   21: 5.671381242573261,\n",
       "   22: 2.025473989546299,\n",
       "   23: 1.0613913908600807,\n",
       "   24: 2.4815588891506195,\n",
       "   25: 2.549630805850029,\n",
       "   26: 1.5453027859330177,\n",
       "   27: 6.011972937732935,\n",
       "   28: 1.837255522608757}),\n",
       " (1219,\n",
       "  {0: 4.855426348745823,\n",
       "   1: 3.1140450835227966,\n",
       "   2: 2.763053484261036,\n",
       "   3: 2.560890018939972,\n",
       "   4: 3.8708794713020325,\n",
       "   5: 6.365799963474274,\n",
       "   6: 4.000025816261768,\n",
       "   7: 2.716604381799698,\n",
       "   8: 2.5182759761810303,\n",
       "   9: 1.5872319750487804,\n",
       "   10: 2.43452051281929,\n",
       "   11: 2.4796270169317722,\n",
       "   12: 1.98419139534235,\n",
       "   13: 2.646535098552704,\n",
       "   14: 1.7531918920576572,\n",
       "   15: 2.1229416839778423,\n",
       "   16: 2.5220945328474045,\n",
       "   17: 1.663754127919674,\n",
       "   18: 1.8456894978880882,\n",
       "   19: 3.1087077409029007,\n",
       "   20: 3.9539266750216484,\n",
       "   21: 2.4523550048470497,\n",
       "   22: 1.7054667472839355,\n",
       "   23: 3.693016953766346,\n",
       "   24: 5.22263352945447,\n",
       "   25: 4.200196214020252,\n",
       "   26: 2.4606404080986977}),\n",
       " (1222,\n",
       "  {0: 12.725758492946625,\n",
       "   1: 9.959106266498566,\n",
       "   2: 8.937601000070572,\n",
       "   3: 3.55649197101593,\n",
       "   4: 18.416346967220306,\n",
       "   5: 2.520941972732544}),\n",
       " (1233,\n",
       "  {0: 11.710079804062843,\n",
       "   1: 1.1628666520118713,\n",
       "   2: 3.5708011835813522,\n",
       "   3: 3.3930934965610504,\n",
       "   4: 5.701527021825314,\n",
       "   5: 8.102452173829079,\n",
       "   6: 4.865803401917219,\n",
       "   7: 2.968115344643593,\n",
       "   8: 2.9969320222735405,\n",
       "   9: 2.9398537650704384,\n",
       "   10: 4.233501672744751,\n",
       "   11: 2.852275427430868,\n",
       "   12: 2.514535214751959,\n",
       "   13: 2.3691092170774937,\n",
       "   14: 1.7129165567457676,\n",
       "   15: 1.8055722415447235,\n",
       "   16: 1.887021578848362,\n",
       "   17: 1.8058520257472992,\n",
       "   18: 3.028839647769928,\n",
       "   19: 2.9372061155736446,\n",
       "   20: 2.8008168265223503,\n",
       "   21: 1.7129272818565369}),\n",
       " (1272,\n",
       "  {0: 8.332681961357594,\n",
       "   1: 0.7664349973201752,\n",
       "   2: 3.449771597981453,\n",
       "   3: 3.5116748735308647,\n",
       "   4: 3.217221312224865,\n",
       "   5: 4.328934486955404,\n",
       "   6: 4.756091184914112,\n",
       "   7: 4.77933232113719,\n",
       "   8: 3.618865881115198,\n",
       "   9: 3.088630635291338,\n",
       "   10: 4.433445319533348,\n",
       "   11: 1.52018503844738,\n",
       "   12: 2.4658528864383698,\n",
       "   13: 0.9343249052762985,\n",
       "   14: 3.8001026250422,\n",
       "   15: 0.7999021708965302,\n",
       "   16: 1.1864123344421387,\n",
       "   17: 1.3846856951713562,\n",
       "   18: 4.158854801207781,\n",
       "   19: 5.761082276701927,\n",
       "   20: 1.790741227567196,\n",
       "   21: 0.8645205497741699,\n",
       "   22: 2.2165954187512398,\n",
       "   23: 4.201795380562544,\n",
       "   24: 1.2349367141723633,\n",
       "   25: 1.875547043979168,\n",
       "   26: 0.3381945863366127}),\n",
       " (1311,\n",
       "  {0: 6.409048944711685,\n",
       "   1: 4.441712826490402,\n",
       "   2: 5.336097717285156,\n",
       "   3: 2.554734706878662,\n",
       "   4: 3.7997030168771744,\n",
       "   5: 4.152061820030212,\n",
       "   6: 2.1628396436572075,\n",
       "   7: 7.068089053034782,\n",
       "   8: 4.065175723284483,\n",
       "   9: 2.340362187474966,\n",
       "   10: 3.513158902525902,\n",
       "   11: 3.149003315716982,\n",
       "   12: 2.1346227191388607,\n",
       "   13: 2.6911794170737267,\n",
       "   14: 2.3603405244648457,\n",
       "   15: 2.111803751438856,\n",
       "   16: 2.601147811859846,\n",
       "   17: 2.399306818842888,\n",
       "   18: 5.069672420620918,\n",
       "   19: 4.419512324035168,\n",
       "   20: 2.1295238733291626}),\n",
       " (1324,\n",
       "  {0: 5.67918036878109,\n",
       "   1: 3.4127818644046783,\n",
       "   2: 2.8871829099953175,\n",
       "   3: 2.867387279868126,\n",
       "   4: 2.158116430044174,\n",
       "   5: 2.337972514331341,\n",
       "   6: 2.7505821771919727,\n",
       "   7: 2.824538718909025,\n",
       "   8: 0.8959182798862457,\n",
       "   9: 2.9595387428998947,\n",
       "   10: 2.06317550316453,\n",
       "   11: 1.4224409349262714,\n",
       "   12: 1.9964390471577644,\n",
       "   13: 1.6540509425103664,\n",
       "   14: 1.9766787365078926,\n",
       "   15: 4.3148215264081955,\n",
       "   16: 1.860091745853424,\n",
       "   17: 3.9921331219375134,\n",
       "   18: 2.133049838244915,\n",
       "   19: 4.614574311301112,\n",
       "   20: 1.2466336973011494,\n",
       "   21: 3.1450764760375023,\n",
       "   22: 3.4789090789854527,\n",
       "   23: 3.9936523027718067,\n",
       "   24: 6.405356839299202,\n",
       "   25: 3.869759738445282,\n",
       "   26: 2.723975159227848}),\n",
       " (1352,\n",
       "  {0: 10.923062764108181,\n",
       "   1: 1.735695481300354,\n",
       "   2: 5.674131765961647,\n",
       "   3: 5.96819331496954,\n",
       "   4: 4.155859921127558,\n",
       "   5: 3.1965841203927994,\n",
       "   6: 1.7532945573329926,\n",
       "   7: 0.6043401286005974,\n",
       "   8: 1.1090251840651035,\n",
       "   9: 1.5739525817334652,\n",
       "   10: 1.0446857511997223,\n",
       "   11: 1.4697378501296043,\n",
       "   12: 0.5474993139505386,\n",
       "   13: 1.1113096289336681,\n",
       "   14: 1.5759825259447098,\n",
       "   15: 1.0705567002296448,\n",
       "   16: 3.594535678625107,\n",
       "   17: 0.7574609220027924,\n",
       "   18: 1.38141855224967,\n",
       "   19: 1.3254546970129013,\n",
       "   20: 1.292979046702385,\n",
       "   21: 1.580818384885788,\n",
       "   22: 0.859823614358902,\n",
       "   23: 1.6286509409546852,\n",
       "   24: 0.5905988775193691,\n",
       "   25: 1.079583428800106,\n",
       "   26: 2.2061877399683,\n",
       "   27: 1.8533560931682587,\n",
       "   28: 5.6067703776061535,\n",
       "   29: 1.1766927987337112,\n",
       "   30: 1.1261812448501587,\n",
       "   31: 1.7813264206051826,\n",
       "   32: 0.7460937350988388,\n",
       "   33: 1.3673203513026237,\n",
       "   34: 1.8049998637288809,\n",
       "   35: 1.9593955390155315,\n",
       "   36: 3.581365257501602,\n",
       "   37: 1.899344440549612,\n",
       "   38: 0.31076468527317047}),\n",
       " (1363,\n",
       "  {0: 6.2555204927921295,\n",
       "   1: 0.7589001357555389,\n",
       "   2: 3.6569308936595917,\n",
       "   3: 2.9642620757222176,\n",
       "   4: 1.5921550020575523,\n",
       "   5: 3.1839358061552048,\n",
       "   6: 3.0195878446102142,\n",
       "   7: 1.469052080065012,\n",
       "   8: 1.1888735890388489,\n",
       "   9: 2.7376802414655685,\n",
       "   10: 10.235644608736038,\n",
       "   11: 6.845791187137365,\n",
       "   12: 1.547331765294075,\n",
       "   13: 4.307062704116106,\n",
       "   14: 11.18415530025959,\n",
       "   15: 1.8282832726836205,\n",
       "   16: 1.3635614030063152,\n",
       "   17: 1.9144223630428314,\n",
       "   18: 2.9319288469851017,\n",
       "   19: 6.807579930871725,\n",
       "   20: 2.811272297054529,\n",
       "   21: 3.028312537819147}),\n",
       " (1382,\n",
       "  {0: 3.794366732239723,\n",
       "   1: 2.5411618053913116,\n",
       "   2: 3.389178916811943,\n",
       "   3: 0.636555939912796,\n",
       "   4: 2.27406657487154,\n",
       "   5: 1.9006818532943726,\n",
       "   6: 1.4890670627355576,\n",
       "   7: 1.924999788403511,\n",
       "   8: 2.8045006096363068,\n",
       "   9: 1.6459747403860092,\n",
       "   10: 1.805777132511139,\n",
       "   11: 2.8725143522024155,\n",
       "   12: 1.6746302843093872,\n",
       "   13: 1.391708493232727,\n",
       "   14: 2.523200936615467,\n",
       "   15: 5.491315245628357,\n",
       "   16: 1.0536044016480446,\n",
       "   17: 0.9070027880370617,\n",
       "   18: 1.5821116492152214,\n",
       "   19: 1.346859872341156,\n",
       "   20: 1.4588232636451721,\n",
       "   21: 2.8490835689008236,\n",
       "   22: 3.152278060093522,\n",
       "   23: 1.4120330475270748,\n",
       "   24: 1.6519871950149536,\n",
       "   25: 0.6898629926145077,\n",
       "   26: 2.179970033466816,\n",
       "   27: 0.9845864102244377,\n",
       "   28: 0.8996876105666161,\n",
       "   29: 2.0763666331768036,\n",
       "   30: 0.9784893468022346,\n",
       "   31: 0.7823166623711586,\n",
       "   32: 1.327193807810545,\n",
       "   33: 0.8261348903179169,\n",
       "   34: 2.6494587175548077,\n",
       "   35: 1.7800517231225967,\n",
       "   36: 1.4921844564378262,\n",
       "   37: 3.1337998658418655,\n",
       "   38: 2.3859552182257175,\n",
       "   39: 2.3822911009192467,\n",
       "   40: 1.9132062941789627,\n",
       "   41: 1.7855530455708504,\n",
       "   42: 0.4991282969713211}),\n",
       " (1386,\n",
       "  {0: 16.555209457874298,\n",
       "   1: 9.490627631545067,\n",
       "   2: 9.363788038492203,\n",
       "   3: 6.361918732523918,\n",
       "   4: 7.756097465753555,\n",
       "   5: 6.328043222427368,\n",
       "   6: 5.961166590452194,\n",
       "   7: 2.0199832916259766}),\n",
       " (1389,\n",
       "  {0: 33.104207932949066,\n",
       "   1: 5.210561633110046,\n",
       "   2: 12.805905520915985,\n",
       "   3: 3.7441760301589966}),\n",
       " (1523,\n",
       "  {0: 7.039998337626457,\n",
       "   1: 3.7265271320939064,\n",
       "   2: 3.5156370252370834,\n",
       "   3: 1.6021201089024544,\n",
       "   4: 1.8630076013505459,\n",
       "   5: 1.121567577123642,\n",
       "   6: 1.4502827301621437,\n",
       "   7: 3.3370141983032227,\n",
       "   8: 1.9434863924980164,\n",
       "   9: 3.8875128850340843,\n",
       "   10: 1.897471435368061,\n",
       "   11: 1.6033881343901157,\n",
       "   12: 1.629191555082798,\n",
       "   13: 1.0812212526798248,\n",
       "   14: 2.3533187210559845,\n",
       "   15: 1.5071660839021206,\n",
       "   16: 1.2115099392831326,\n",
       "   17: 1.595971167087555,\n",
       "   18: 0.8990741074085236,\n",
       "   19: 1.6506685949862003,\n",
       "   20: 2.76226906478405,\n",
       "   21: 0.8637504279613495,\n",
       "   22: 1.878682415932417,\n",
       "   23: 0.9802269339561462,\n",
       "   24: 0.7450529485940933,\n",
       "   25: 1.0474294312298298,\n",
       "   26: 1.8441635221242905,\n",
       "   27: 0.7173234820365906,\n",
       "   28: 0.8408847153186798,\n",
       "   29: 1.7144322395324707,\n",
       "   30: 1.8568433597683907,\n",
       "   31: 1.256309386342764,\n",
       "   32: 2.2245182022452354,\n",
       "   33: 4.007231570780277,\n",
       "   34: 0.9382479935884476,\n",
       "   35: 1.3154838755726814,\n",
       "   36: 2.229241255670786,\n",
       "   37: 1.0057057589292526,\n",
       "   38: 0.7255995348095894,\n",
       "   39: 0.9520426690578461,\n",
       "   40: 0.5132092386484146,\n",
       "   41: 1.4667272418737411,\n",
       "   42: 0.7531417906284332,\n",
       "   43: 1.386975109577179,\n",
       "   44: 1.4614201188087463,\n",
       "   45: 0.6079762428998947,\n",
       "   46: 0.8238982930779457}),\n",
       " (1532,\n",
       "  {0: 11.501927316188812,\n",
       "   1: 2.954976439476013,\n",
       "   2: 7.279187873005867,\n",
       "   3: 5.4086931720376015,\n",
       "   4: 5.628445528447628,\n",
       "   5: 6.758570119738579,\n",
       "   6: 20.557268016040325,\n",
       "   7: 3.564952053129673,\n",
       "   8: 3.6092525124549866,\n",
       "   9: 1.1945295929908752}),\n",
       " (1536,\n",
       "  {0: 16.0200934112072,\n",
       "   1: 6.048139333724976,\n",
       "   2: 12.672865450382233,\n",
       "   3: 9.682618513703346,\n",
       "   4: 8.516037046909332,\n",
       "   5: 1.5921109318733215}),\n",
       " (1611,\n",
       "  {0: 6.078538879752159,\n",
       "   1: 4.644912213087082,\n",
       "   2: 1.026138722896576,\n",
       "   3: 4.005877956748009,\n",
       "   4: 2.107523739337921,\n",
       "   5: 1.7531284093856812,\n",
       "   6: 5.744045943021774,\n",
       "   7: 2.3649615049362183,\n",
       "   8: 2.046194475144148,\n",
       "   9: 1.4383211694657803,\n",
       "   10: 1.500524252653122,\n",
       "   11: 3.0648520439863205,\n",
       "   12: 3.5159902535378933,\n",
       "   13: 1.2569339014589787,\n",
       "   14: 1.3298528790473938,\n",
       "   15: 2.01148971170187,\n",
       "   16: 1.4222856312990189,\n",
       "   17: 1.022311259061098,\n",
       "   18: 1.2142524719238281,\n",
       "   19: 2.181432232260704,\n",
       "   20: 1.9730832464993,\n",
       "   21: 1.0565325766801834,\n",
       "   22: 0.9807108640670776,\n",
       "   23: 3.001327283680439,\n",
       "   24: 3.250512979924679,\n",
       "   25: 2.211819525808096,\n",
       "   26: 1.1081179454922676,\n",
       "   27: 1.3097072094678879,\n",
       "   28: 4.235325753688812,\n",
       "   29: 3.2838170416653156,\n",
       "   30: 1.1633183024823666,\n",
       "   31: 1.570779949426651,\n",
       "   32: 2.784054756164551,\n",
       "   33: 1.7617231607437134,\n",
       "   34: 1.2422702312469482}),\n",
       " (1615,\n",
       "  {0: 6.364447265863419,\n",
       "   1: 1.1179271638393402,\n",
       "   2: 4.634595587849617,\n",
       "   3: 4.520519405603409,\n",
       "   4: 2.49129705876112,\n",
       "   5: 5.542866617441177,\n",
       "   6: 4.370908409357071,\n",
       "   7: 1.7035591155290604,\n",
       "   8: 2.3782883547246456,\n",
       "   9: 1.5975308269262314,\n",
       "   10: 1.8499950170516968,\n",
       "   11: 1.8068589270114899,\n",
       "   12: 2.407343864440918,\n",
       "   13: 1.3286039382219315,\n",
       "   14: 1.8237461745738983,\n",
       "   15: 3.4388356134295464,\n",
       "   16: 3.7834860794246197,\n",
       "   17: 1.401088960468769,\n",
       "   18: 1.7070847935974598,\n",
       "   19: 1.642794132232666,\n",
       "   20: 5.229672521352768,\n",
       "   21: 2.4260760098695755,\n",
       "   22: 1.9833695702254772,\n",
       "   23: 1.4606356211006641,\n",
       "   24: 1.585468351840973,\n",
       "   25: 1.429620549082756,\n",
       "   26: 2.9115599542856216,\n",
       "   27: 2.5007236301898956,\n",
       "   28: 2.100293219089508,\n",
       "   29: 1.3542810678482056}),\n",
       " (1650,\n",
       "  {0: 9.292099088430405,\n",
       "   1: 1.6606493294239044,\n",
       "   2: 4.108859896659851,\n",
       "   3: 6.147930175065994,\n",
       "   4: 9.17503209412098,\n",
       "   5: 7.536703996360302,\n",
       "   6: 4.229969754815102,\n",
       "   7: 3.294461190700531,\n",
       "   8: 6.189760163426399,\n",
       "   9: 2.6863564550876617,\n",
       "   10: 6.415723450481892,\n",
       "   11: 3.63294979929924,\n",
       "   12: 1.8386447429656982}),\n",
       " (1679,\n",
       "  {0: 22.09635379910469,\n",
       "   1: 6.495962709188461,\n",
       "   2: 8.714417308568954,\n",
       "   3: 2.610387995839119,\n",
       "   4: 2.8365170657634735,\n",
       "   5: 5.423508673906326,\n",
       "   6: 2.625617541372776,\n",
       "   7: 2.580756187438965,\n",
       "   8: 3.134563833475113,\n",
       "   9: 4.390288025140762,\n",
       "   10: 2.0967536568641663,\n",
       "   11: 3.387706011533737,\n",
       "   12: 1.3650698065757751}),\n",
       " (1689,\n",
       "  {0: 8.693277552723885,\n",
       "   1: 4.5975745022296906,\n",
       "   2: 4.029689289629459,\n",
       "   3: 3.222612038254738,\n",
       "   4: 3.4458185769617558,\n",
       "   5: 1.8245196789503098,\n",
       "   6: 2.0955862998962402,\n",
       "   7: 3.447959117591381,\n",
       "   8: 3.036227911710739,\n",
       "   9: 2.682312995195389,\n",
       "   10: 4.320105232298374,\n",
       "   11: 4.6504814103245735,\n",
       "   12: 2.9387384206056595,\n",
       "   13: 2.935158409178257,\n",
       "   14: 1.4390295445919037,\n",
       "   15: 1.8519213199615479,\n",
       "   16: 3.8856165930628777,\n",
       "   17: 5.257734514772892,\n",
       "   18: 3.347679689526558,\n",
       "   19: 2.8767671808600426,\n",
       "   20: 1.6023134738206863,\n",
       "   21: 1.784451812505722,\n",
       "   22: 2.153698056936264,\n",
       "   23: 1.2250421047210693}),\n",
       " (1733,\n",
       "  {0: 9.784455761313438,\n",
       "   1: 5.924554407596588,\n",
       "   2: 1.8255447149276733,\n",
       "   3: 3.6464588344097137,\n",
       "   4: 4.108398377895355,\n",
       "   5: 6.140554666519165,\n",
       "   6: 1.4642331823706627,\n",
       "   7: 2.543639052659273,\n",
       "   8: 4.637398175895214,\n",
       "   9: 5.5451885387301445,\n",
       "   10: 2.1980787217617035,\n",
       "   11: 3.043361511081457,\n",
       "   12: 3.0597630329430103,\n",
       "   13: 4.52210808172822,\n",
       "   14: 2.0090017542243004,\n",
       "   15: 1.7320301979780197,\n",
       "   16: 1.8896768614649773,\n",
       "   17: 1.6357008144259453,\n",
       "   18: 1.9670878946781158,\n",
       "   19: 2.7943241596221924,\n",
       "   20: 1.9043980240821838,\n",
       "   21: 2.2859698832035065,\n",
       "   22: 1.3100531101226807}),\n",
       " (1755,\n",
       "  {0: 9.702610969543457,\n",
       "   1: 5.1563365906476974,\n",
       "   2: 5.829059287905693,\n",
       "   3: 3.1206119880080223,\n",
       "   4: 5.346751049160957,\n",
       "   5: 2.7626062780618668,\n",
       "   6: 3.403079077601433,\n",
       "   7: 4.841856300830841,\n",
       "   8: 4.830867409706116,\n",
       "   9: 2.941397041082382,\n",
       "   10: 3.4156641513109207,\n",
       "   11: 4.176766272634268,\n",
       "   12: 1.8496555536985397,\n",
       "   13: 2.101873964071274,\n",
       "   14: 2.5321590155363083,\n",
       "   15: 3.883785240352154,\n",
       "   16: 7.12861093878746,\n",
       "   17: 2.232144355773926}),\n",
       " (1768,\n",
       "  {0: 6.208475850522518,\n",
       "   1: 0.7880089282989502,\n",
       "   2: 4.921386569738388,\n",
       "   3: 1.6844336912035942,\n",
       "   4: 2.255199983716011,\n",
       "   5: 1.9212200567126274,\n",
       "   6: 1.817632533609867,\n",
       "   7: 2.4790962412953377,\n",
       "   8: 2.584104001522064,\n",
       "   9: 2.3427254259586334,\n",
       "   10: 1.624053731560707,\n",
       "   11: 2.6099330112338066,\n",
       "   12: 3.440423898398876,\n",
       "   13: 1.8796395510435104,\n",
       "   14: 1.1955449841916561,\n",
       "   15: 2.0227450001984835,\n",
       "   16: 3.1028919219970703,\n",
       "   17: 1.857139566913247,\n",
       "   18: 1.9341108053922653,\n",
       "   19: 1.435747191309929,\n",
       "   20: 1.9121019504964352,\n",
       "   21: 2.11793596111238,\n",
       "   22: 0.5289919413626194,\n",
       "   23: 1.272812906652689,\n",
       "   24: 1.4638897683471441,\n",
       "   25: 4.097183765843511,\n",
       "   26: 1.6757573038339615,\n",
       "   27: 1.3531511276960373,\n",
       "   28: 0.7616177648305893,\n",
       "   29: 1.2892730459570885,\n",
       "   30: 1.8094868063926697,\n",
       "   31: 2.025363840162754,\n",
       "   32: 4.404764637351036,\n",
       "   33: 1.385079339146614,\n",
       "   34: 0.69568882137537,\n",
       "   35: 1.2874689474701881,\n",
       "   36: 0.8305798470973969,\n",
       "   37: 1.427303060889244,\n",
       "   38: 2.4283226765692234,\n",
       "   39: 1.7416627258062363,\n",
       "   40: 0.25620823726058006}),\n",
       " (1806,\n",
       "  {0: 9.381891772150993,\n",
       "   1: 5.46045295894146,\n",
       "   2: 9.176327973604202,\n",
       "   3: 4.312235936522484,\n",
       "   4: 3.136295735836029,\n",
       "   5: 5.853764250874519,\n",
       "   6: 5.91014139354229,\n",
       "   7: 4.543166346848011,\n",
       "   8: 2.982438787817955,\n",
       "   9: 2.866627477109432,\n",
       "   10: 3.3973744213581085,\n",
       "   11: 3.3158640153706074,\n",
       "   12: 3.137241579592228,\n",
       "   13: 2.318738676607609,\n",
       "   14: 3.4631558507680893,\n",
       "   15: 2.140650749206543}),\n",
       " (1810,\n",
       "  {0: 10.230048850178719,\n",
       "   1: 2.7582404613494873,\n",
       "   2: 6.662415489554405,\n",
       "   3: 3.631426766514778,\n",
       "   4: 4.192839417606592,\n",
       "   5: 5.47594877332449,\n",
       "   6: 15.125743471086025,\n",
       "   7: 3.4786586686968803,\n",
       "   8: 2.7483234219253063,\n",
       "   9: 2.927450980991125,\n",
       "   10: 1.6514219269156456,\n",
       "   11: 7.828593395650387,\n",
       "   12: 3.1969197168946266,\n",
       "   13: 2.6405975371599197,\n",
       "   14: 1.1943084001541138}),\n",
       " (1819,\n",
       "  {0: 23.048378139734268,\n",
       "   1: 17.195984482765198,\n",
       "   2: 12.219320088624954,\n",
       "   3: 2.5475270748138428}),\n",
       " (1837,\n",
       "  {0: 10.27430373430252,\n",
       "   1: 4.937581479549408,\n",
       "   2: 3.9987021684646606,\n",
       "   3: 3.4009736627340317,\n",
       "   4: 2.830404132604599,\n",
       "   5: 1.610079824924469,\n",
       "   6: 2.792535111308098,\n",
       "   7: 2.6480318009853363,\n",
       "   8: 2.2076691538095474,\n",
       "   9: 1.993523072451353,\n",
       "   10: 2.2894011959433556,\n",
       "   11: 1.744509231299162,\n",
       "   12: 1.0219991207122803,\n",
       "   13: 1.7419889010488987,\n",
       "   14: 1.8221631683409214,\n",
       "   15: 0.888747638091445,\n",
       "   16: 1.5580227617174387,\n",
       "   17: 1.8029682077467442,\n",
       "   18: 1.5317140184342861,\n",
       "   19: 0.8967521488666534,\n",
       "   20: 1.7072667963802814,\n",
       "   21: 1.613375160843134,\n",
       "   22: 0.8399139530956745,\n",
       "   23: 1.5127472393214703,\n",
       "   24: 1.889983408153057,\n",
       "   25: 1.5026200711727142,\n",
       "   26: 0.9493540301918983,\n",
       "   27: 1.7765893042087555,\n",
       "   28: 1.9786371551454067,\n",
       "   29: 1.008994534611702,\n",
       "   30: 1.8735493309795856,\n",
       "   31: 2.301865477114916,\n",
       "   32: 0.9975434318184853,\n",
       "   33: 2.112977370619774,\n",
       "   34: 2.5007640458643436,\n",
       "   35: 1.070864461362362,\n",
       "   36: 0.5391086116433144}),\n",
       " (1846,\n",
       "  {0: 9.094424068927765,\n",
       "   1: 6.856541499495506,\n",
       "   2: 7.715073853731155,\n",
       "   3: 4.823821499943733,\n",
       "   4: 8.186753019690514,\n",
       "   5: 6.0709263458848,\n",
       "   6: 6.757629252970219,\n",
       "   7: 4.48881371319294,\n",
       "   8: 5.663966603577137}),\n",
       " (1857,\n",
       "  {0: 8.858112871646881,\n",
       "   1: 5.708200171589851,\n",
       "   2: 4.949896343052387,\n",
       "   3: 2.8395951092243195,\n",
       "   4: 3.837613105773926,\n",
       "   5: 3.5447749942541122,\n",
       "   6: 6.545735917985439,\n",
       "   7: 2.667742371559143,\n",
       "   8: 2.2934896610677242,\n",
       "   9: 2.46867486089468,\n",
       "   10: 4.342687390744686,\n",
       "   11: 3.387003466486931,\n",
       "   12: 3.578319363296032,\n",
       "   13: 3.1073420643806458,\n",
       "   14: 6.867793053388596,\n",
       "   15: 3.4354506731033325,\n",
       "   16: 1.7983590364456177})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_level_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 116 is out of bounds for dimension 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- unconditionally build the line‐score dict ---\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m st_scores = \u001b[43msubtoken_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m.cpu()\n\u001b[32m      3\u001b[39m st2line   = sub2line[i]\n\u001b[32m      4\u001b[39m line2scores = {}\n",
      "\u001b[31mIndexError\u001b[39m: index 116 is out of bounds for dimension 0 with size 10"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_fun_preds  = []\n",
    "all_fun_labels = []\n",
    "all_line_preds  = []\n",
    "all_line_labels = []\n",
    "line_level_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    fn_global_idx = 0\n",
    "    for b in test_loader:\n",
    "        input_ids      = b[\"input_ids\"].to(device)\n",
    "        attention_mask = b[\"attention_mask\"].to(device)\n",
    "        labels         = b[\"labels\"].to(device)       # (batch_size,)\n",
    "        sub2line       = b[\"subtoken2line\"]           # (batch_size, seq_len)\n",
    "        flaw_lines     = b[\"flaw_line_no\"]             # list of length batch_size\n",
    "\n",
    "        out     = model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        logits  = out.logits           # (batch_size, 2)\n",
    "        fun_preds = logits.argmax(dim=1).cpu().tolist()\n",
    "\n",
    "        #Accumulate function-level predictions/labels\n",
    "        all_fun_preds.extend(fun_preds)\n",
    "        all_fun_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "        #Build subtoken-level “CLS→subtoken” scores\n",
    "        all_attn   = out.attentions   #is a tuple of length 12 (one tensor per Transformer layer).\n",
    "        # Stack dims → (12, batch, heads, seq_len, seq_len)\n",
    "        attn_tensor = torch.stack(all_attn, dim=0)\n",
    "        # Sum over heads → (12, batch, seq_len, seq_len)\n",
    "        attn_per_layer = attn_tensor.sum(dim=2)\n",
    "        # Sum over layers → (batch, seq_len, seq_len)\n",
    "        attn_sum = attn_per_layer.sum(dim=0)\n",
    "        # subtoken_scores[i, j] = attention from CLS (pos 0) → subtoken j of example i\n",
    "        subtoken_scores = attn_sum[:, 0, :]   # (batch_size, seq_len)\n",
    "\n",
    "        batch_size = logits.size(0)\n",
    "        for i in range(batch_size):\n",
    "            if fun_preds[i] == 1:\n",
    "                #Gather subtoken‐scores for example i\n",
    "                st_scores = subtoken_scores[i].cpu()     # (seq_len,)\n",
    "                st2line   = sub2line[i]                  # (seq_len,)\n",
    "\n",
    "                #Build line2subtoken‐scores map\n",
    "                line2scores = {}\n",
    "                for tok_idx in range(st2line.size(0)):\n",
    "                    ln = st2line[tok_idx].item()\n",
    "                    if ln < 0:\n",
    "                        continue\n",
    "                    score_j = st_scores[tok_idx].item()\n",
    "                    line2scores.setdefault(ln, []).append(score_j)\n",
    "\n",
    "                #Sum each line’s scores\n",
    "                line2score_sum = {ln: sum(scores) for ln, scores in line2scores.items()}\n",
    "\n",
    "                #Pick the line with the highest summed score\n",
    "                if len(line2score_sum) > 0:\n",
    "                    sorted_lines = sorted(line2score_sum.items(),\n",
    "                                          key=lambda x: x[1],\n",
    "                                          reverse=True)\n",
    "                    pred_line = sorted_lines[0][0]\n",
    "                else:\n",
    "                    # If somehow every token was padding (line2score_sum empty), pick -1\n",
    "                    pred_line = -1\n",
    "\n",
    "                line_level_results.append((fn_global_idx, line2score_sum))\n",
    "            else:\n",
    "                # Model predicted “clean” → no line predicted\n",
    "                pred_line = -1\n",
    "\n",
    "            # e) Accumulate predicted line & true line\n",
    "            all_line_preds.append(pred_line)\n",
    "\n",
    "            # If flaw_lines[i] is a list (e.g. [5]), take the first element; else treat it as int\n",
    "            gt = flaw_lines[i]\n",
    "            if isinstance(gt, (list, tuple)) and len(gt) > 0:\n",
    "                true_line = gt[0]\n",
    "            elif isinstance(gt, (list, tuple)) and len(gt) == 0:\n",
    "                true_line = -1\n",
    "            else:\n",
    "                true_line = gt\n",
    "            all_line_labels.append(true_line)\n",
    "\n",
    "            fn_global_idx += 1\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Function‐level metrics (over the entire test set)\n",
    "# ----------------------------------------------------------------------------\n",
    "test_acc  = accuracy_score(all_fun_labels, all_fun_preds)\n",
    "test_prec = precision_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_rec  = recall_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_f1   = f1_score(all_fun_labels, all_fun_preds, zero_division=0)\n",
    "test_mcc  = matthews_corrcoef(all_fun_labels, all_fun_preds)\n",
    "print(f\"Function‐level (test) → \"\n",
    "      f\"acc={test_acc:.3f}, prec={test_prec:.3f}, rec={test_rec:.3f}, \"\n",
    "      f\"f1={test_f1:.3f}, mcc={test_mcc:.3f}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "#show Top-10 ranked lines for the first vulnerable function\n",
    "# ----------------------------------------------------------------------------\n",
    "if len(line_level_results) > 0:\n",
    "    first_fn_idx, first_line2score_dict = line_level_results[0]\n",
    "    sorted_lines0 = sorted(first_line2score_dict.items(),\n",
    "                           key=lambda x: x[1],\n",
    "                           reverse=True)\n",
    "    top10_0 = sorted_lines0[:10]\n",
    "    print(f\"\\nFunction #{first_fn_idx} → top-10 lines by summed attention:\\n  {top10_0}\")\n",
    "\n",
    "\n",
    "# Top-K precision (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul = 0\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    # if true_line < 0:\n",
    "    #     continue\n",
    "    total_vul += 1\n",
    "    ranked_lines = [\n",
    "        ln for (ln, _) \n",
    "        in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    if true_line in ranked_lines[:K]:\n",
    "        hits += 1\n",
    "\n",
    "if total_vul > 0:\n",
    "    topk_precision = hits / total_vul\n",
    "else:\n",
    "    topk_precision = 0.0\n",
    "\n",
    "print(f\"Top-{K} precision (vulnerable-only) = {topk_precision:.3f}\")\n",
    "\n",
    "# Top-K recall (e.g. K = 10)\n",
    "K = 10\n",
    "hits = 0\n",
    "total_vul = 0\n",
    "for i in range(len(all_line_labels)):\n",
    "    true_line = all_line_labels[i]\n",
    "    if true_line < 0:\n",
    "        continue\n",
    "    total_vul += 1\n",
    "    line2score_dict = line_level_results[i][1]\n",
    "    ranked_lines = [\n",
    "        ln for (ln, _) \n",
    "        in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    if true_line in ranked_lines[:K]:\n",
    "        hits += 1\n",
    "total_real=len()\n",
    "if total_vul > 0:\n",
    "    topk_precision = hits / total_vul\n",
    "else:\n",
    "    topk_precision = 0.0\n",
    "\n",
    "print(f\"Top-{K} precision (vulnerable-only) = {topk_precision:.3f}\")\n",
    "\n",
    "# Initial False Alarm (IFA)\n",
    "ifa_list = []\n",
    "for (fn_idx, line2score_dict) in line_level_results:\n",
    "    true_line = all_line_labels[fn_idx]\n",
    "    if true_line < 0:\n",
    "        continue\n",
    "    ranked_lines = [\n",
    "        ln for (ln, _) \n",
    "        in sorted(line2score_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    if true_line in ranked_lines:\n",
    "        pos = ranked_lines.index(true_line)\n",
    "    else:\n",
    "        pos = len(ranked_lines)\n",
    "    ifa_list.append(pos)\n",
    "\n",
    "if len(ifa_list) > 0:\n",
    "    avg_ifa = sum(ifa_list) / len(ifa_list)\n",
    "else:\n",
    "    avg_ifa = 0.0\n",
    "\n",
    "print(f\"Initial False Alarm (average) = {avg_ifa:.2f} lines before true flaw\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DXbK3lSyvfI2"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "009903730bec4c45a94d6a4478000123": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01d740979f47467c94233b7aac08e31b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "030607ef6fe84fee8007446cb509be61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0902c22a5bce4a6f896091e4c96beacf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bba0ab96300c4bb691d4d025168e8fc2",
      "max": 150,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fa9410ef174243b1988a0aa63ca38cfe",
      "value": 150
     }
    },
    "0c872cc3525f442f8f85c35a9a283bc9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d5dccf3b8dc4808955bf6ad18cf1bf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13151feabdd544dfbfbd017e17fc19d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2324fa453fe7472f80d7e71a12b7abc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92c3444219c149e4b28798bee888572c",
      "placeholder": "​",
      "style": "IPY_MODEL_ca2f67bcf60c48a69d82e49bc967785a",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "2831f175c58d4df1bdca7ab51580a585": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b83c333bc50847b4ba38bf6a976c3b7e",
      "placeholder": "​",
      "style": "IPY_MODEL_35ffec9c3ef84ac285f5847c0ceddcc0",
      "value": " 498/498 [00:00&lt;00:00, 46.0kB/s]"
     }
    },
    "33a7a108cae44c90a8182e3c75f6b379": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34a20f6a820d454f82a7b61577a8dc1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35ffec9c3ef84ac285f5847c0ceddcc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3622c40246cd4c418d6b0be87a8eabe3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "369498116cac4ae09ff455d632984758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a53b42b225a4cb29a961c1d81049f35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d907c30a2634364a64a67d7c20f15d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45a8dd922bc84cc49c510210c966b5b2",
      "placeholder": "​",
      "style": "IPY_MODEL_6dc3d89349054aa9a4110c5a7ae7dd99",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "45a8dd922bc84cc49c510210c966b5b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "471d804ae7a24a43a9399d9a17619ad6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb7d16a76f1648f6b78f586ef17f15e0",
      "placeholder": "​",
      "style": "IPY_MODEL_a295f1a203a841ea937ed2796d661c39",
      "value": "config.json: 100%"
     }
    },
    "5002419487374b57a0c980d4b1f5da65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e32d8a695f1840c294cd9ba2976a8e16",
       "IPY_MODEL_88db3fceb1bd44179d99cc39587e9586",
       "IPY_MODEL_a4851453b1964050949d9e0a3d16cfd6"
      ],
      "layout": "IPY_MODEL_789146f0550f450b8de66097ec4fdd6c"
     }
    },
    "51b80a11294f424288d7539fc45cfa4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d43f29792b54570ad9b1dd50a1262de",
       "IPY_MODEL_53a9dfd96b1e47b78cbce4e062b39462",
       "IPY_MODEL_caa8bd91464349a1b92334130fea76cc"
      ],
      "layout": "IPY_MODEL_d34b79f8c0714e8c8fdd27328bbfc7a1"
     }
    },
    "53a9dfd96b1e47b78cbce4e062b39462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c872cc3525f442f8f85c35a9a283bc9",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4c07e26a7fd4efb82e55d2ba6fa37cd",
      "value": 456318
     }
    },
    "54558508893243a8bb3321534afbfd5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5bdba9b6b9d4fe68fa3a222765a8ca9",
      "max": 498627950,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f458b5f7eb504a278197b582f54e1bd7",
      "value": 498627950
     }
    },
    "5a32dc9aa429446091b7ab8ef05ae20a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a8ac4b97dca414b94e2170dbff02bb1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d357f25578342dbad22b27ba5cbb4e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d43f29792b54570ad9b1dd50a1262de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a32dc9aa429446091b7ab8ef05ae20a",
      "placeholder": "​",
      "style": "IPY_MODEL_0d5dccf3b8dc4808955bf6ad18cf1bf0",
      "value": "merges.txt: 100%"
     }
    },
    "62fa3750a9214b2490ad224e944f89ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69573b28181845149006d06ce4fdc507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbf48451f87941f68966efd1ba925a23",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b3c759498934dd1bfd9c76505fcb198",
      "value": 25
     }
    },
    "6dc3d89349054aa9a4110c5a7ae7dd99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "789146f0550f450b8de66097ec4fdd6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88db3fceb1bd44179d99cc39587e9586": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cfccbba007d7490cb09739f6584f2ae8",
      "max": 898822,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_369498116cac4ae09ff455d632984758",
      "value": 898822
     }
    },
    "89e16a41ffbf4e0a91d91ce27d227373": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33a7a108cae44c90a8182e3c75f6b379",
      "placeholder": "​",
      "style": "IPY_MODEL_b316b07cb00a4fb98d8ba74bddec984e",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "92c3444219c149e4b28798bee888572c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9474e9198d374b1c8ca205d2d83c2124": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f44ae5924b324f44bde6ad47e63f4dd9",
      "placeholder": "​",
      "style": "IPY_MODEL_3a53b42b225a4cb29a961c1d81049f35",
      "value": " 150/150 [00:00&lt;00:00, 12.4kB/s]"
     }
    },
    "9b3c759498934dd1bfd9c76505fcb198": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d5873d8a2144f8faff06d7e4ec5a1d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a295f1a203a841ea937ed2796d661c39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4851453b1964050949d9e0a3d16cfd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13151feabdd544dfbfbd017e17fc19d9",
      "placeholder": "​",
      "style": "IPY_MODEL_b01c584a5a7345c6ac7ff9d9c29e54bd",
      "value": " 899k/899k [00:00&lt;00:00, 1.86MB/s]"
     }
    },
    "a4c07e26a7fd4efb82e55d2ba6fa37cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a94edc754a394f129191401639ab4fa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_030607ef6fe84fee8007446cb509be61",
      "placeholder": "​",
      "style": "IPY_MODEL_62fa3750a9214b2490ad224e944f89ad",
      "value": " 25.0/25.0 [00:00&lt;00:00, 2.36kB/s]"
     }
    },
    "b01c584a5a7345c6ac7ff9d9c29e54bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b316b07cb00a4fb98d8ba74bddec984e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b83c333bc50847b4ba38bf6a976c3b7e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bba0ab96300c4bb691d4d025168e8fc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3da7d04467f40c0a3a54a26e0726bb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2324fa453fe7472f80d7e71a12b7abc3",
       "IPY_MODEL_54558508893243a8bb3321534afbfd5a",
       "IPY_MODEL_cff83c7534024690bce996b8796bf112"
      ],
      "layout": "IPY_MODEL_34a20f6a820d454f82a7b61577a8dc1f"
     }
    },
    "c6722170c28740daa126611c56aec406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca2f67bcf60c48a69d82e49bc967785a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caa8bd91464349a1b92334130fea76cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_faa7b2e9d4434f59b4025d4f0672b28f",
      "placeholder": "​",
      "style": "IPY_MODEL_cbf48700257d43f7871b6e6628e950ba",
      "value": " 456k/456k [00:00&lt;00:00, 1.04MB/s]"
     }
    },
    "cb886794d1de40ddba2b138be2b27e9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_89e16a41ffbf4e0a91d91ce27d227373",
       "IPY_MODEL_69573b28181845149006d06ce4fdc507",
       "IPY_MODEL_a94edc754a394f129191401639ab4fa6"
      ],
      "layout": "IPY_MODEL_c6722170c28740daa126611c56aec406"
     }
    },
    "cbf48451f87941f68966efd1ba925a23": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbf48700257d43f7871b6e6628e950ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf77bdf9eda84326b2f8c4a8adc592b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd1b5619e2a64b46bd6dd48b1328dd59",
      "max": 498,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01d740979f47467c94233b7aac08e31b",
      "value": 498
     }
    },
    "cfccbba007d7490cb09739f6584f2ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cff83c7534024690bce996b8796bf112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_009903730bec4c45a94d6a4478000123",
      "placeholder": "​",
      "style": "IPY_MODEL_d6173d8cd2614d63a1787ba9ad70c132",
      "value": " 499M/499M [00:01&lt;00:00, 250MB/s]"
     }
    },
    "d34b79f8c0714e8c8fdd27328bbfc7a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5bdba9b6b9d4fe68fa3a222765a8ca9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6173d8cd2614d63a1787ba9ad70c132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e32d8a695f1840c294cd9ba2976a8e16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a8ac4b97dca414b94e2170dbff02bb1",
      "placeholder": "​",
      "style": "IPY_MODEL_5d357f25578342dbad22b27ba5cbb4e9",
      "value": "vocab.json: 100%"
     }
    },
    "f1727ee3799c458f8e16b2d8b884d671": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3d907c30a2634364a64a67d7c20f15d5",
       "IPY_MODEL_0902c22a5bce4a6f896091e4c96beacf",
       "IPY_MODEL_9474e9198d374b1c8ca205d2d83c2124"
      ],
      "layout": "IPY_MODEL_9d5873d8a2144f8faff06d7e4ec5a1d3"
     }
    },
    "f44ae5924b324f44bde6ad47e63f4dd9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f458b5f7eb504a278197b582f54e1bd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa9410ef174243b1988a0aa63ca38cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "faa7b2e9d4434f59b4025d4f0672b28f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb7d16a76f1648f6b78f586ef17f15e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb97bd4362f048e495107e6b06c7b070": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_471d804ae7a24a43a9399d9a17619ad6",
       "IPY_MODEL_cf77bdf9eda84326b2f8c4a8adc592b8",
       "IPY_MODEL_2831f175c58d4df1bdca7ab51580a585"
      ],
      "layout": "IPY_MODEL_3622c40246cd4c418d6b0be87a8eabe3"
     }
    },
    "fd1b5619e2a64b46bd6dd48b1328dd59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
